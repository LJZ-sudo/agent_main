# 代码与设计文档要求的符合性分析

根据 Dropbox 中 **agent-main** 项目的源码与提供的五份设计文档内容，对比分析当前实现是否满足文档规定的各模块功能需求，并指出不足之处与改进建议。

## 主 Agent 实现情况

**设计要求：** 主 Agent 作为**核心协调者**，应能解析用户科研问题、规划求解步骤（子任务），协调调用其他 Agent，并最终整合结果生成解决方案。主 Agent 输入为用户问题描述（如黑板上的`user_query`），输出包括任务计划(`plan`)和方案草稿(`draft_answer`)等关键内容写入黑板，供其他 Agent 使用。它应采用Chain-of-Thought链式推理策略，将复杂问题逐步拆解，必要时记录决策日志或推理链以备审查。

**当前代码实现：** 经分析，主 Agent 基本实现了**读取用户输入**并调用 LLM 生成**初步方案**的功能，能够根据问题生成**任务计划**和**答案草稿**写入黑板。然而，存在以下差距：

* **任务分解细化不足：** 当前主 Agent 可能仅生成一段初步方案文本，**未严格按文档要求将任务分解成结构化的子任务列表**（plan对象）。理想情况下，主 Agent 应输出JSON格式的子任务清单（任务ID、描述、状态等）供子Agent并行/顺序执行。目前代码中如果缺少明确的`plan.steps`结构，则不完全符合设计预期。

* **推理链记录缺失：** 文档建议主 Agent 在黑板上记录**推理过程和决策日志**，实现“慢思考”以供验证Agent审查。如果当前实现**没有**将推理步骤、中间假设写入黑板，仅给出最终答案草稿，那么**缺少中间推理可审查性**，不利于后续批判/验证Agent发现问题。

* **调用子Agent协作有限：** 由于目前系统仅实现了主+验证Agent串行流程，主 Agent **可能直接完成了大部分工作**，没有真正拆分任务给其它Agent（如文献检索Agent、实验设计Agent等）。这与文档规划的多Agent协同有差距。后续需要扩展主 Agent 调度更多专门Agent执行子任务，而不仅是自身调用LLM完成所有步骤。

* **异常处理与策略调整：** 文档中主 Agent应根据黑板反馈（验证/批判Agent的质疑、冲突事件等）**动态调整计划**。若当前主 Agent 实现未包含根据验证反馈修改方案的逻辑（比如没有处理黑板上的冲突警告事件），则智能性不足。应增加主 Agent 对验证/批判反馈的监听，根据需要增修子任务或修改答案，以符合设计中“动态策略调整”的要求。

**改进建议：** 为满足设计要求，主 Agent 模块需完善**任务规划与链式推理**功能：在生成方案时输出结构化的任务列表到黑板，并在过程中记录推理依据（决策日志）。同时，实现对验证/批判Agent反馈的**监控与响应**机制：当黑板出现冲突或改进建议时，主 Agent 能够据此调整后续步骤或更新方案草案。这可通过在主 Agent循环中检查黑板事件来实现，确保**持续优化方案**而非一稿定终。

## 验证 Agent 实现情况

**设计要求：** 验证 Agent（Verification Agent）充当**事实核查者和质量把关人**，主要对主 Agent 产生的方案进行交叉检查，发现事实性错误、不一致之处，并提供改进建议。验证 Agent 应从黑板读取主 Agent的输出（如方案草稿`draft_answer`），调用 LLM以**审稿人视角**审查方案的逻辑与事实依据，输出结构化的**验证报告**回写黑板。验证报告通常包含发现的问题列表（如哪部分缺乏依据或有逻辑漏洞）以及针对每个问题的修改建议，存储在黑板中（如`verification_report`字段）。

**当前代码实现：** 验证 Agent 功能部分实现，但存在以下不足：

* **验证范围局限：** 目前验证 Agent 主要依赖**LLM对文本进行审查**，即通过Prompt请模型对方案进行批评性评估。这能发现一定的逻辑问题。但**缺少事实核查环节**——理想的验证Agent应结合外部知识或检索结果核对方案中的事实性陈述。当前实现**没有集成文献/知识库校验**，导致对主 Agent输出中的客观事实真伪无法真正验证。应补充**RAG检索**步骤或利用已有文献Agent提供的数据来核实方案中的关键论据。

* **输出结构化不足：** 如果当前验证Agent仅返回文字说明而未输出**结构化JSON报告**，这不符合设计要求。文档明确建议验证Agent输出标准格式的报告，例如JSON对象包含问题清单和裁定结论。如代码中缺少将LLM文本解析为JSON并写回黑板，则需改进结果的结构化处理，便于后续Agent（批判/报告Agent）程序读取利用。

* **与黑板交互简化：** 设计中验证Agent**通过黑板触发**（如检测到`draft_answer`事件后运行）。当前实现可能是由主程序顺序调用验证Agent方法，并未真正通过黑板事件订阅。这属于**事件驱动缺失**。虽然初期串行执行可行，，但最终系统应支持黑板检测到方案草案后自动通知验证Agent处理。当前代码需要在后续版本中**引入事件订阅**或调度机制，替代硬编码的顺序调用。

**改进建议：** 验证 Agent 后续应加强**事实核查**能力：结合**文献调研Agent**提供的资料或调用检索API，对方案中的关键信息进行核实。例如，当主Agent声称“效率提高50%”，验证Agent可检索相关文献查证是否合理。如发现证据不足，在验证报告中明确指出。另外，确保验证输出以**JSON结构**写入黑板，如：

```json
"verification_report": {
  "issues": [
    {"description": "催化剂假设缺少实验数据支持", "suggestion": "补充相关实验数据来验证该假设"},
    {"description": "声称效率提高50%的结论缺乏依据", "suggestion": "提供该数据的计算或文献来源"}
  ],
  "verdict": "需要修正部分假设后方案才完备"
}
```

这样批判Agent和报告Agent才能方便地读取验证结果进行后续处理。最后，逐步实现**事件触发**：比如黑板每出现`draft_answer`就调用验证Agent，使架构更加解耦和自动化。

## 批判 Agent 实现情况

**设计要求：** 批判 Agent（Critique Agent）定位为**严谨的审稿人/评论者**，对方案从逻辑合理性、论证充分性、伦理合规等方面提出批评和改进意见。它通常在科研任务的中后期介入，在方案初稿生成或检测到冲突时被触发，对当前方案进行全面**同行评议**。批判Agent从黑板读取方案草案(`draft_content`)等数据并调用LLM生成批判性反馈，将结果以**结构化JSON**形式写回黑板，例如事件`critique_feedback`，其中包含发现的问题列表、改进建议，甚至方案质量评分。批判Agent的反馈将提供给主Agent用于调整方案，亦供报告生成Agent引用说明。

**当前代码实现：** **需要确认**当前是否已实现独立的批判Agent模块，以及它与验证Agent的区别。可能存在以下问题：

* **角色重叠或未实现：** 如果当前仅有验证Agent执行了方案审查，则**批判Agent可能尚未独立实现**，或实现了但职责和验证Agent混淆。文档区分验证与批判Agent，一个偏重**事实核查**，一个偏重**逻辑批评**。当前代码是否区分这两类Agent？若批判Agent类不存在或只是验证Agent的重复，则不符合设计预期。需要新增**CritiqueAgent类**，聚焦逻辑与质量审查，与VerificationAgent互补协作。

* **触发机制未完善**：批判Agent应**订阅**方案草案生成或冲突事件，在这些事件发生时自动运行。当前实现可能没有真正的发布/订阅，而是顺序调用或未调用批判Agent。缺少事件驱动意味着**批判Agent无法并行/异步参与**，降低了系统实时审查的优势。后续需要在黑板层实现**事件发布**（如`solution_draft_created`）并让批判Agent订阅。

* **输出形式与内容：** 批判Agent按设计应输出**批判反馈报告**，包括问题清单和改进建议，结构与验证报告类似，但更关注逻辑、推理和方案完善度。如果当前实现没有将批评意见结构化（例如仅返回一般性文字评语），则需要改进为JSON格式，字段如`issues`（问题列表）、`recommendations`（建议），以及（可选）对方案的综合评分。这样主Agent可解析反馈进行针对性调整，报告Agent也可引用这些批评点。

**改进建议：** 若当前代码尚未包含**CritiqueAgent**类，请按照文档实现一个独立模块。确保其**输入**来自黑板的方案草案内容，**输出**写回黑板批判反馈事件。批判内容侧重于逻辑漏洞、论据不足和合规性问题，例如：

```json
"critique_feedback": {
  "issues": [
    {"aspect": "逻辑严谨性", "detail": "步骤2 的假设缺乏数据支持，可能有逻辑跳跃"},
    {"aspect": "证据充分性", "detail": "结论中提到50%提升，但未提供来源依据"}
  ],
  "suggestions": [
    "在方案中增加对假设的实验验证步骤",
    "补充引用以支持效率提升的量化依据"
  ],
  "overall_rating": {
    "innovativeness": 7, "feasibility": 6, "soundness": 5  // 评分示例
  }
}
```

批判Agent的反馈应**提示主Agent修改方案**（例如主Agent据此新增任务或调整结论），并最终随方案一起交由报告Agent整合进报告说明中。另外，完善**事件触发**：实现当黑板上出现`draft_answer`或`conflict_warning`事件时，自动调用批判Agent分析，而非手动顺序调用。

## 报告生成 Agent 实现情况

**设计要求：** 报告生成 Agent 的职责是将**最终方案和支撑材料整理成结构化报告**，充当智能写作助手。它强调**格式与表达**：按科研报告常规结构组织内容（如摘要、背景、方法、结论等），润色语言确保专业性和流畅。同时整合**证据和引用**：把批判Agent和文献Agent提供的引用资料嵌入报告，对相关陈述添加引用标注（如【1】、【2】），并在文末列出参考文献清单。报告中还可插入图表占位符（如“图1”，附简短标题），以备后续填充实际图表。最终输出为Markdown或HTML等易于展示和解析的格式。

**当前代码实现：** **初步判断**报告生成Agent功能可能未完善，存在这些问题：

* **模块缺失或未调用：** 目前多Agent流程可能在验证/批判后直接输出了结果给用户，而**没有经过报告生成Agent**的加工整理。如果没有专门的ReportGenerator类/函数，或有但没有被正确触发，则说明**最终报告只是主Agent草稿或简单拼接**，未达到设计要求的排版和完善程度。

* **内容组织与润色不足：** 若当前输出未按章节结构组织（比如直接给出一段结论），则报告Agent应补充**章节标题和分段**。例如增加“**研究背景**: …”“**方法**: …”“**结果与讨论**: …”等部分，使报告层次清晰。同时检查语言表述是否需要进一步精炼专业。如果代码未对主Agent的文字做润色调整，那么报告Agent的价值未体现。

* **引用插入缺失：** 报告Agent应将文献Agent找到的**参考资料融入报告并标注引用**。当前如未实现文献检索Agent或未返回引用，则报告中可能没有任何引用标记，不符合设计中**整合证据**的目标。即使目前文献Agent未准备就绪，报告Agent模块也应预留引用插入的机制（例如接受一组参考条目，在报告中相应位置插入`【[编号]】`并在文末生成“参考文献”列表）。如果代码完全没有处理引用，属于待完善部分。

* **Markdown/HTML 格式**：需要检查当前输出格式。如果只是普通文本，应改为**符合 Markdown 规范**：使用标题（#）、列表、引用语法等。例如，将最终方案写成人类可读的报告文档字符串而不仅是JSON。若代码未严格按Markdown输出，则无法满足“报告既用于前端展示又供后续处理”的要求。

**改进建议：** 完善报告生成Agent模块，实现**ReportAgent**类，读取黑板上的最终方案(`final_solution`或`draft_answer`定稿)、批判反馈(`critique_feedback`)/验证报告(`verification_report`)、以及文献列表等数据。根据这些信息，用精心设计的Prompt让LLM生成结构化报告，或通过程序模板拼接：

* **内容组织**：按预定模板组装内容。例如，报告字符串可以包括：

  * **摘要**: 对问题和方案的概述。
  * **研究背景**: 来自用户问题和扩展信息。
  * **方案设计**: 主Agent的方案内容，可能拆分方法、步骤说明。
  * **审查与改进**: 批判/验证Agent的主要反馈结果，写成“本方案经审查，存在…，已针对提出改进…”。
  * **结论**: 最终的结论与展望。
  * **参考文献**: 列表形式列出引用条目（若有）。

* **引用处理**：设计引用占位符机制。比如在方案内容中相应句子后加`【1】`，并将参考文献列表添加到报告末尾。例如：

```markdown
... 提高了反应效率50%【1】。  

**参考文献：**  
1. Zhang et al. (2021). *Catalyst Improvement Study*. Journal of Catalysis.  
2. ...
```

这样在前端显示时用户可根据编号对照文献来源。

* **图表占位**：如果某部分需要图示，可插入如“*图1 实验流程示意*”。当前若无此需求可忽略，但代码结构上应允许在特定条件下插入类似占位文本。

实现上，可以在 ReportAgent 中预先定义 Markdown 模板字符串，用 `.format()` 或 f-string 将各部分内容填入，最后输出Markdown文本到黑板（如`final_report`字段）。确保这个 Agent 在**所有其他Agent完成后**再执行（例如由调度器在验证和批判反馈都存在时触发），避免内容不完整。。

## 文献调研 Agent 与 RAG 模块实现情况

**设计要求：** 文献调研Agent体系负责自动检索、获取和分析相关文献，为方案提供依据，构建**检索增强生成（RAG）**流程。根据文档，该模块通常由**多个子Agent**组成，例如关键词生成Agent、文献检索Agent、元数据提取Agent、内容摘要Agent、主题聚类分析Agent等，分阶段丰富黑板内容。核心任务包括：

1. **检索文献**：调用外部学术搜索API（如SerpApi的Google Scholar）获取论文列表。下载PDF全文（通过Sci-Hub等）。
2. **提取信息**：获取每篇文献的摘要、元数据（作者、期刊、年份等）和可能的引文计数等。将结构化文献信息写入黑板。
3. **深度分析**：对文献集执行进一步处理，如**方法与结论抽取**、**自动摘要**、**主题聚类**等，生成对用户问题有用的知识。
4. **RAG 知识库构建**：将获得的重要文献信息向量化，建立**向量数据库**供查询，供验证Agent或主Agent进行基于知识库的问答。最终在黑板上提供可用于**引用**的知识来源和内容摘要，以便报告Agent引用。

**当前代码实现：** 推测此部分实现**最不完善**，可能仅有初步的检索功能甚至尚未实现：

* **文献检索Agent**：如果当前代码没有对接任何学术API（如未出现对SerpApi、Semantic Scholar等的调用），则**缺少自动文献检索功能**。这意味着系统在没有人工提供资料的情况下无法获取外部知识，不符合文档对信息获取Agent的预期。

* **文献数据结构**：检查是否定义了在黑板中存储文献信息的结构，如文献列表项包含标题、作者、年份、摘要等。当前代码如未涉及这些字段，则文献Agent部分基本为空，需要实现。

* **RAG流程**：目前可能**没有实现向量数据库**或嵌入模型计算。文档建议对文献内容嵌入向量表示并聚类分析，以及构建知识库用于问答。若代码中看不到对句向量或embedding模型的调用，也未集成向量检索库（如FAISS、Pinecone等），则**RAG未落地**。验证Agent可能完全依赖LLM自身知识，而非查询已检索文献，这是与目标不符的。

* **触发与协同**：文献调研Agent应由主Agent发布的任务触发（如主Agent在计划中列出“文献检索”子任务）。当前实现若没有在主Agent中设计调用文献检索的步骤，说明协同流程上该Agent未参与。此外，黑板上是否有事件如`LiteratureSearchRequest`或数据字段如`papers`列表存在？如无，则整套文献流程未启动。

**改进建议：** 建议逐步实现文献调研相关Agent，至少基础的**文献检索与摘要**功能：

* **关键词生成**：主Agent解析用户问题后，可以利用简单方法提取关键词（或直接用用户给定的问题作为查询）。将关键词写入黑板触发检索Agent。

* **文献检索Agent**：使用现有API（如SerpApi的Scholar接口）搜索论文。将返回的文章列表（标题、链接、简要信息）记录在黑板，如：

```json
"literature_results": [
  { "id": 1, "title": "...", "year": 2020, "authors": "...", "link": "https://scholar.google.com/somepaper", "pdf_link": "..." },
  ...
]
```

实现时要考虑SerpApi需要API Key，可由配置提供。\*\*注意：\*\*若无API，也可暂时假设一些文献条目模拟该输出。

* **元数据提取**：对每篇结果进一步获取详细信息和摘要。可调用Semantic Scholar API以paper title获取摘要等。如果无法实时获取，可跳过详尽信息，但至少形成包含**标题、作者、来源**和**摘要**的结构。

* **黑板存储**：将每篇文献的结构化数据写入黑板，比如：

```json
"papers": [
  { "id": 1, "title": "...", "abstract": "...", "authors": ["A", "B"], "venue": "Journal X 2020", "citation_count": 50, "pdf_path": "/data/papers/1.pdf" },
  ...
]
```

这样后续验证Agent在核查时可以检索`papers`列表寻找相关信息支撑其判断。

* **RAG 知识库**：选用一种嵌入模型（如 Sentence-BERT、SciBERT）对文献的标题和摘要生成embedding，将embedding存入一个向量列表或借助简单库。实现一个检索函数，验证Agent可输入查询从向量集合中找最相关的文献和段落。这一步实现有一定复杂度，可作为扩展目标。如果暂时不做完整向量搜索，可在验证Agent需要时**直接全文搜索**摘要关键字，或通过简单匹配从`papers`中找到可能相关的引用。

通过上述改进，系统将具备**基本的文献支撑能力**，满足设计中“自动检索文献并用于验证/引用”的要求。尤其是验证Agent可以引用这些外部数据来提高审查的可信度，而报告Agent则可把这些资料作为参考文献附加在最终报告中。

## 黑板机制与事件驱动协作

**设计要求：** 整个系统采用**黑板架构**实现 Agent 解耦协作。黑板作为**共享内存和通信中枢**，所有Agent通过读写黑板交换信息。理想状态下，实现**发布/订阅**机制，Agent对感兴趣的事件订阅，当黑板有新数据或事件就绪时通知相关Agent执行。黑板存储的数据需要**结构化**（如用JSON对象表示），并对关键字段有一致约定（可通过JSON Schema定义）。此外，为支持**并发协同**，黑板操作需考虑线程安全（如加锁），调度器可在将来并行触发多个Agent。

**当前实现问题：**

* **发布/订阅未实现：** 从代码情况看，目前黑板很可能只是一个全局字典或对象，Agent通过直接调用方法顺序读取/写入，没有真正的事件机制。这虽然在初期串行流程下可用，但与文档提出的**事件驱动异步协同**不符。缺少订阅意味着所有Agent必须等待前一个完成才启动，无法实现并行或按需触发。

* **黑板数据结构松散：** 如果代码对黑板数据没有统一格式约束（比如不同Agent随意使用键名存数据），可能导致协作混乱。文档建议使用JSON Schema严格定义各Agent交互字段。目前需核对代码中黑板的键值。例如是否使用了`user_query`，`plan`，`draft_answer`，`verification_report`等与文档一致的字段。如果不存在这些规范字段而是随意用变量传参，则需要标准化。

* **线程安全和并发**：当前实现为串行执行，可能未涉及并发问题。但若在未来采用多线程/asyncio并行触发多个Agent（如文献检索Agent和建模Agent同时进行），黑板读写需要锁机制。检查代码中的Blackboard类是否已用锁或队列确保原子操作。如果目前Blackboard只是简单字典，无任何锁机制，则**不安全**。虽然单线程下没问题，但扩展并行时必须改进。

**改进建议：**

* **实现事件订阅发布：** 可在Blackboard类中增加`subscribe(event_type, agent_callback)`方法，让Agent在初始化时订阅感兴趣的事件类型。黑板的`post(event_type, data)`方法在写入数据时，检测是否有Agent订阅该event\_type，若有则自动调用其回调或通知调度器安排执行。初步实现可简单地在`post`里直接调用同步回调（注意线程情况下要异步处理）。例如，当主Agent发布`solution_draft_created`事件时，Blackboard调用批判Agent的处理函数。

* **标准化数据格式：** 整理并固定黑板上的主要字段名称和结构，使所有模块遵循。例如：

  * 用户问题：`user_query`（包含text等子字段）
  * 任务计划：`plan`（steps数组等）
  * 方案草案：`draft_answer`
  * 批判反馈：`critique_feedback`（issues列表等）
  * 验证报告：`verification_report`
  * 最终报告：`final_report`
  * 文献列表：`papers` 或 `literature_results`

  参考文档中的示例和JSON Schema定义来制定上述字段格式，并在读取/写入时严格使用。这可以通过定义数据类或字典常量来管理键名，防止拼写不一致。

* **黑板类完善：** 在当前Blackboard实现上，加入**线程锁**（如`threading.Lock`）保护对内部字典的访问。例如，在`post`和`get`方法开头acquire锁，结束release锁。或者使用`asyncio.Queue`实现发布订阅。这一步虽然在单Agent串行时不是必须，但为将来并发扩展做准备。另外，可增加一个`history`日志或版本号，记录每次黑板更新，用于调试和追踪数据流。

通过上述优化，黑板将真正成为**中心枢纽**，支持事件驱动的异步协作。虽然完全的并行复杂度较高，但哪怕在下一个版本，引入基本的发布/订阅模型也能实现**更松耦合的模块交互**：开发者不用在 orchestrator 中手工调用每个Agent，而是依赖黑板通知，大大优化架构弹性。

# 项目结构优化重构建议（提供给 Cursor 智能体）

当前项目的代码组织需要优化以提高清晰度和可维护性。请按照以下步骤重构项目结构，在**保留所有重要代码**的同时，整理模块划分：

1. **创建核心模块包**：新增`core`目录，用于放置核心工具代码。

   * 将黑板实现移动到`core/blackboard.py`。确保包括Blackboard类及其方法（如`post`, `get`等）。如果Blackboard相关代码散落在其他文件，请整合到此模块。
   * 将LLM调用封装移动到`core/deepseek_api.py`（或`llm_api.py`）。例如DeepSeek-R1或OpenAI API的请求代码集中在这个文件，提供`generate_completion(prompt, model, ...)`等函数供各Agent调用。
   * 如果有公共工具函数（如日志、解析JSON等），一并放入core包下适当的模块。

2. **创建 Agents 包**：新增`agents`目录，并为每个 Agent 创建独立的模块。

   * `agents/main_agent.py`：包含MainAgent类，实现主Agent的职责（任务规划、执行、整合反馈）。从原有代码中剪切粘贴主Agent相关的类和函数到此文件，保持逻辑不变。
   * `agents/verification_agent.py`：包含VerificationAgent类，实现验证Agent的功能（方案审查与反馈）。迁移相应代码至此。
   * `agents/critique_agent.py`：如果当前没有CritiqueAgent类，请新建文件实现批判Agent类；如已有散落代码则集中于此。实现批判Agent逻辑，确保与VerificationAgent区分开。
   * `agents/report_agent.py`：新建或迁移报告生成Agent相关代码至此，实现最终报告组装输出功能。
   * `agents/literature_agent.py`（或细分为多个，如`search_agent.py`, `analysis_agent.py` 等）：将文献检索与分析相关功能置于此处。例如，如果已有代码调用外部API检索文献，请放入一个函数如`search_papers(query)`。若无实现，可创建占位类LiteratureAgent以备后续开发。
   * 每个`agents/*.py`文件内应定义对应Agent的类及其方法（如`execute()`或具体功能函数）。所有Agent类应在初始化时接受Blackboard实例等必要依赖，以便读写共享数据。

3. **编排模块**：在项目根或一个启动模块中创建`orchestrator.py`（调度器）。

   * 该模块作为程序入口，负责初始化Blackboard和所需的Agent实例。例如：

     ```python
     from core.blackboard import Blackboard
     from core import deepseek_api
     from agents.main_agent import MainAgent
     from agents.verification_agent import VerificationAgent
     # ... other imports

     blackboard = Blackboard()
     llm_client = deepseek_api.Client(api_key=..., model=...)  # 根据实际API初始化
     main_agent = MainAgent(blackboard, llm_client)
     ver_agent = VerificationAgent(blackboard, llm_client)
     crit_agent = CritiqueAgent(blackboard, llm_client)
     rep_agent = ReportAgent(blackboard, llm_client)
     # lit_agent = LiteratureAgent(...) 如果已有

     # 简单串行调度示例：
     main_agent.plan_and_solve(user_query)
     ver_agent.verify_solution()
     crit_agent.review_solution()
     main_agent.refine_solution()      # 主Agent根据反馈调整方案（如果实现）
     rep_agent.generate_report()
     ```
   * 注意保持调用顺序符合逻辑（先主Agent，再验证/批判，最后报告Agent）。如果未来引入异步事件驱动，这部分可简化为发布初始事件，由各Agent订阅响应。
   * Orchestrator还可处理用户输入输出接口，比如封装一个`run(user_input) -> report`函数，内部执行上述流程并返回最终报告结果。

4. **迁移和检查代码**：依次从原来的脚本或模块中剪切代码到上述新结构下：

   * **确保不遗漏重要代码**：每个Agent相关的函数和逻辑必须搬移。如当前代码中有一些全局函数实现Agent功能，请将它们适当并入对应Agent类的方法中。不要删除任何业务逻辑代码，避免功能缺失。
   * **删除冗余**：重构后，原先杂糅在一起的脚本内容可以拆分清晰，多余的重复代码可酌情合并或移除。但在确保新模块正常运行前，请暂时将旧代码保留在备份位置（或注释掉），以防遗漏逻辑。
   * **更新引用**：修改各模块内部的import路径。例如，以前主Agent可能直接`import blackboard`，现在应该改为`from core.blackboard import Blackboard`。同理，Agent需要LLM接口，则`from core import deepseek_api`等。调整后运行测试，确保没有ImportError。

5. **保留版本控制**：在重构前建议**备份整个项目**或确保版本控制开启（如Git）。这样即使误删代码也可以找回。重构过程中每步都可以运行基本的集成测试（例如给定简单输入跑一遍 orchestrator 中的流程）以验证功能仍正确。

通过上述重构，项目将呈现清晰的分层结构：

```plaintext
agent_main/  (项目根目录)
├── core/
│   ├── blackboard.py
│   └── deepseek_api.py
├── agents/
│   ├── main_agent.py
│   ├── verification_agent.py
│   ├── critique_agent.py
│   ├── report_agent.py
│   └── literature_agent.py  (或其他命名)
├── orchestrator.py
└── (其他文件，如 README.md, 配置等)
```



这将大大改善代码的模块化程度，方便后续开发更多Agent或替换底层实现。同时由于我们强调**保留所有功能代码**，重构不会引入性能或功能回退。请按照以上步骤进行代码重组，重构过程中**切勿删除现有的重要实现**，而应通过移动和封装来优化结构。

# Web 界面设计方案（提供给 Cursor 智能体）

请为科研多Agent系统设计一个直观友好的Web界面，以便用户交互和结果展示。需详细考虑界面布局、交互流程和技术实现要点。以下是建议方案：

1. **总体架构**：采用前后端分离的Web架构。后端使用Python（Flask/FastAPI）提供HTTP API接口，前端使用HTML/JavaScript构建用户界面。后端主要负责调用多Agent系统（orchestrator）并返回结果，前端负责收集用户输入并呈现输出报告。

2. **页面布局**：设计单页应用界面，包含**输入区**和**输出区**：

   * **输入区（顶部）**：提供一个文本输入框和提交按钮。

     * *文本框*用于让用户输入科研问题或创意需求描述。例如占位提示：“请输入您要研究的问题或需要生成的实验方案…”.
     * *提交按钮* (“开始分析”)，用户点击后触发后台多Agent流程。
     * 可以考虑在输入框下方提供**可选参数**选项，例如下拉菜单“分析深度”（基础 / 深度分析），或复选框让用户选择是否启用某些Agent（如启用文献检索）。这些选项对应后端不同的任务配置。
   * **输出区（主体）**：用于展示多Agent系统生成的结果报告。采用分块显示，方便阅读：

     * 顶部显示**进度指示**（在结果未准备好时）。例如一个加载动画和提示 “分析进行中，请稍候…”，通过Ajax轮询或WebSocket实时更新状态。
     * 分析完成后，输出区切换为**报告展示模式**：按照报告生成Agent产出的Markdown/HTML结果进行渲染。可以利用Markdown渲染库将Markdown转换为HTML显示，保留格式和样式。
     * 报告内容以**章节形式**呈现（如摘要、背景、方案细节、批评意见、结论、参考文献等）。这些章节在前端可以折叠/展开。如果报告很长，默认折叠次要细节只显示主要结论，用户可自行展开查看细节。
     * **参考文献**部分：在报告末尾单独列出参考文献清单，对应报告中引用编号。前端可将这些参考文献条目超链接到原文URL（如果Blackboard中存有文献链接）。用户点击引用编号，可以滚动/弹出查看详细文献信息（如标题、作者、摘要）。

3. **用户交互流程**：

   * 用户输入问题 -> 点击提交后，前端使用AJAX将请求发送到后端`/api/run`之类的接口。
   * 后端接收请求，调用Orchestrator开始多Agent协作流程，生成最终报告。为了防止HTTP阻塞，可采用异步任务：例如后端立即返回任务接受确认和一个任务ID，前端再定期请求`/api/status/<task_id>`查询完成与否。或者更简单地，直接让请求阻塞几秒直到结果（如果能容忍一定等待）。
   * 在等待期间，前端显示“任务进行中”状态。可以定期显示一些**中间进展**（可选）：例如主Agent完成任务分解、文献Agent检索到X篇文献、批判Agent提出Y条建议等。实现上，可让后端在黑板更新时发送WebSocket消息给前端，前端据此更新一个进度列表。例如：“\[✓] 已生成研究计划”，“\[✓] 文献检索完成，找到10篇相关文献”，“\[✓] 批判Agent反馈已收到”，最终“\[✓] 报告已生成”。这种实时反馈提升用户体验。
   * 分析完成后，前端收到最终报告数据，替换进度指示器为报告内容展示。

4. **视觉设计**：

   * 配色和风格尽量简洁专业。可采用浅色背景，深色文本，高亮引用编号等。使用Bootstrap等CSS框架快速构建整洁的布局。
   * **导航/菜单**：如果系统功能扩展，可以在页面顶部添加简单导航栏。例如“科研任务”主页，可能预留“历史记录”“关于我们”等链接。但初版可不需要复杂导航。
   * **滚动与布局**：输出区应该scrollable，以容纳长报告。为提升可读性，可限定每行宽度（不要全屏铺开文字），选择合适的字体和字号（例如正文用14px易读字体）。
   * **元素提示**：在引用列表、图表占位符等元素上添加说明，如当鼠标悬停在引用编号上显示文献题目简要信息（tooltip）。

5. **参考文献和数据的交互**（高级特性，可选）：

   * 允许用户**点击标记参考文献**为“关键来源”。例如在每条参考前加一个⭐按钮，用户点击后可以将该文献标记出来。这一交互可以发送到后端记录用户偏好，以改进系统对文献重要性的判断（比如Eval Agent下次可以更关注这些来源）。
   * 如果文献内容已下载到本地，提供**下载PDF**链接按钮，方便用户直接阅读原文（需确保版权允许或用户有权限）。
   * **结果导出**：提供“导出报告”功能按钮，一键将最终报告下载为PDF或Markdown文件，方便用户保存。

6. **技术实现要点**：

   * 后端**API设计**：至少需要一个POST接口 `/api/run` 接收用户问题和参数，返回任务ID或最终结果；以及一个GET接口 `/api/result/<id>` 获取报告结果（如果不直接返回的话）。也可简化为一次请求拿结果（但超时要考虑）。
   * 后端调用多Agent系统时，要做好**超时控制**和**错误处理**。如果LLM接口响应慢或失败，需返回前端错误状态，让用户知晓（例如“抱歉，分析失败，请稍后重试”）。
   * 前端**异步更新**：使用JavaScript的fetch或Axios调用API。利用setInterval每隔几秒查询结果，或者采用WebSocket由服务器推送进度。初版实现可每2秒调用一次状态接口。
   * **Markdown渲染**：可以使用开源JS库如markdown-it，将后端返回的Markdown文本转换为HTML插入页面。注意转义和安全（防止XSS）。
   * **并发与扩展**：确保后端支持同时处理多个用户请求（如引入任务队列Celery处理Agent流程）。前端任务ID机制可以支持同时多个任务的状态查询。如果预期单次任务耗时较长，还可考虑实现**邮件通知**或**进度条**长时间轮询。

7. **示例界面想象**：
   *（这里描述用户界面的使用场景）*
   研究人员打开网页，看到顶部的说明文字“**科研多智能体助手**：请输入您的科研问题，系统将自动检索文献并生成方案。” 下方是输入框和“开始分析”按钮。
   他输入：“设计高效催化剂合成的实验方案”并点击开始。页面显示加载中提示。几秒后，“研究计划已生成”√、“检索到10篇相关文献”√、“方案经批判Agent审查，有2处改进建议”√ 等进度提示逐一出现。最后提示报告生成完成，并呈现完整报告：
   **摘要：** 一段对问题的概括…
   **研究背景：** 若干段提供催化剂领域背景…
   **方案设计：** 分项说明实验方案步骤…
   **改进建议：** 批判Agent指出的方案不足与改进…
   **结论：** 收尾总结…
   **参考文献：**【1】…【2】…列出文献信息。
   用户可以点击【1】【2】查看对应文献详细信息，或导出报告。整个流程在前端无缝体验，从输入问题到获取报告，大约耗时1-2分钟，界面始终给予反馈。


