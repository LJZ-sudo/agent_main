非常好，我将为你制定一份详细的架构与模块实施方案，涵盖：

* 你所负责的全部模块（主Agent、验证Agent、批判Agent、报告生成Agent、实验设计Agent、控制调度模块、评估Agent）
* 每个模块的功能目标、输入输出、与黑板及其他Agent的交互方式
* 每个Agent使用LLM进行推理和工作的提示模板（Prompt设计）
* 并考虑与信息获取Agent和建模Agent的接口融合

完成后，我会将该方案组织为便于你用作项目推进的技术参考文档。稍后将通知你查阅。


# 科研创意多Agent系统核心模块技术方案

本技术方案针对科研创意多Agent协同系统的核心模块，提供详细的架构设计和模块说明（不包括信息获取Agent和建模Agent）。系统采用**多Agent+黑板机制**，支持慢思考（逐步推理）、Chain-of-Thought链式推理和多Agent协同反馈。核心模块包括：主Agent、验证Agent、批判Agent、报告生成Agent、实验设计Agent、控制调度模块和评估Agent。下面将对每个模块的功能、数据交互、协作关系、LLM提示模板和交互示例进行说明，并阐述整体架构中各模块与信息获取Agent、建模Agent的融合与协同逻辑。

## 主Agent（Lead/Coordinator）

### 模块功能目标与边界定义

主Agent是系统的**核心协调者**和任务规划者，相当于人类团队的组长或主持人。它负责解析用户提出的科研创意需求或问题陈述，将其拆解为一系列子任务并规划求解步骤。主Agent定义问题边界和求解策略，包括确定需要哪些专门Agent参与，以及任务执行的优先顺序。主Agent自身不执行具体领域任务（如检索、计算），而是在边界内专注于**任务分解、计划调整和结果汇总**。一旦所有必要的子任务完成，主Agent负责整合各模块产出，形成最终的创意方案或实验方案列表，并对方案进行评分排序。主Agent避免越界到具体领域分析（那是各子Agent的职责），其作用边界是决策和调度层面的“元认知”控制。

### 输入输出数据结构说明

* **输入：** 主Agent直接接受**用户输入**的问题描述/创新需求。同时从黑板读取当前任务状态和其他Agent发布的**中间结果**、反馈和事件。关键输入包括：问题规范、已发布的子任务列表、各子任务完成情况，黑板上的警告/冲突事件等。主Agent监视黑板上与全局规划相关的信息，例如“任务完成”事件或批判/验证Agent发布的**冲突警告**。
* **输出：** 主Agent将**任务规划**写入黑板，包括问题解析结果和拆解出的**子任务列表**。每个子任务带有标识、任务类型及描述（例如：“任务1：信息检索—查找X领域文献”）。主Agent也在黑板上发布**任务调度指令**（可以是直接任务事件或通过调用接口触发Agent）。当子任务结果陆续产生，主Agent可能更新黑板上的**计划**（调整任务顺序、新增任务）。在收集所有结果后，主Agent输出**综合方案**到黑板，包括整合的创意方案列表、各方案的评价得分等。该综合方案将供报告生成Agent读取用于生成最终报告。

黑板中，主Agent写入的数据结构包括：**问题规范**（用户需求的结构化表示）、**子任务条目**（任务ID、类型、描述、状态）、**决策日志**（主Agent的推理链条摘要）等。主Agent也会标记任务状态（进行中/已完成）以及记录最终输出的**方案条目**（方案内容、来源引用、评分等）。这些数据以结构化格式存储，例如JSON对象或表格形式，方便其他Agent解析和订阅相应字段。

### 与其他模块的协作机制与依赖关系

主Agent通过**黑板发布/订阅机制**与各子Agent协作。它将子任务发布到黑板，相关专长的Agent（如信息获取Agent、建模Agent等）订阅到相应任务类型后会自行读取任务并执行。在直接调用模式下，主Agent也可以通过系统接口**直接触发**某个Agent执行指定任务。主Agent依赖各子Agent提供专业能力的输出结果；同时，各Agent依赖主Agent提供任务指引和全局上下文。主Agent与**验证Agent**和**批判Agent**呈互补协作关系：批判/验证Agent产生的反馈（如质疑或冲突）会影响主Agent调整后续策略。主Agent也可根据**评估Agent**提供的历史绩效数据调整对各Agent的调用（如优先使用高可靠Agent）。主Agent与**控制调度模块**关系密切——在有独立调度模块时，主Agent专注决策，具体的并发控制和锁管理由调度模块实现；若无独立模块，则主Agent内部实现调度策略。主Agent还负责调用**报告生成Agent**整理最终输出，以及调用**评估Agent**或批判Agent对方案评分。总体来说，主Agent是各模块协作的中枢，维系任务流转和信息共享。

### LLM提示词模板

主Agent内部基于大型语言模型（LLM）实现其规划和元认知功能。通过精心设计提示词，主Agent能够链式思考、多步推理，再将结果写入黑板作为显式计划。以下提供两个主Agent调用LLM的提示模板示例：

* **提示模板 1：初始任务规划**（将用户需求转化为子任务计划）

```text
系统: 你是科研创意协作系统的主Agent，负责任务分解和计划。请根据以下用户需求，解析其关键目标和约束，并产出求解策略。
用户需求: "{用户输入的科研问题或创意需求}"
要求: 
1. 提取任务的研究领域、目标和限制条件。
2. 分解为若干子任务，列出每个子任务的类型（如信息检索、建模计算、实验设计等）和具体内容。
3. 考虑任务间的依赖关系，标注哪些可并行，哪些需顺序执行。
4. 输出格式: 首先给出对问题的理解摘要，然后列出子任务清单 (使用编号)。
```

* **提示模板 2：动态策略调整**（根据中间结果调整计划）

```text
系统: 你是主Agent，正在根据实时进展调整策略。黑板当前已完成的结果和事件汇总如下:
{黑板中各子任务结果摘要和事件列表}
请分析以上进展:
1. 判断是否有子任务未完成却阻碍整体进度（如等待过久或发生冲突事件）。
2. 如有冲突或信息缺失，提出解决方案（例如新增检索任务获取缺失信息，或调用批判Agent分析冲突）。
3. 更新后续计划：给出需要新增或调整的任务清单，或决定跳过某些任务。
4. 输出格式: 简要说明原因，然后列出更新的任务计划/调整措施。
```

上述模板1引导LLM将用户问题**结构化为子任务列表**；模板2用于在运行过程中**反思和调整策略**，让主Agent动态优化计划。通过这些Prompt，主Agent能利用LLM的推理能力实现复杂任务的规划与自适应调度。

### 交互示例

**示例：** 用户提出需求“设计一种高效催化剂合成的实验方案”。主Agent读取用户输入，在黑板上写入对任务的理解和初步计划，例如：**问题**：“高效催化剂合成方案设计”，**任务1**（信息检索）：“查找现有高效催化剂材料文献综述”，**任务2**（建模计算）：“评估候选材料的热力学稳定性”，**任务3**（实验设计）：“制定催化剂合成与测试的实验流程”，**任务4**（评估创新性）：“评估所提方案的新颖性和可行性”。黑板将这些任务发布为事件：信息检索Agent监听到任务1事件，启动执行文献检索；建模Agent获取任务2执行模拟计算。两者并行工作，各自完成后将结果（文献摘要、模拟数据）写回黑板。

主Agent监控黑板，当任务1和2结果出现后，汇总了解到**候选材料A**表现突出但模拟显示高温稳定性一般。此时，主Agent看到文献结果中提到另一种材料B有潜力，于是调整计划：新增**任务2b**（建模计算）：“评估材料B的热稳定性”。控制调度模块根据主Agent的新任务，在有空闲计算资源时触发建模Agent进行材料B模拟。

随后，**实验设计Agent**检测到黑板上已经有“方案骨架”（候选材料A及B的优缺点）以及任务3的发布，就开始工作，设计出详细的实验方案草案（包括如何制备材料A和B、实验步骤、所需设备和评价指标）。**验证Agent**并行地检查黑板内容，发现一个潜在问题：文献Agent提到的材料B需要昂贵催化剂前驱体，可能不具备可行性。验证Agent于是发布**警告事件**：“材料B实验成本过高，现实可行性存疑”。**批判Agent**订阅了“方案草案生成”事件，当实验设计Agent提交了草案后，批判Agent审阅整个方案草稿，对逻辑和创新性进行评估。批判Agent可能在黑板留言：“假设B尽管新颖但成本过高，建议重点优化材料A的方案”。它给材料A方案打分8/10，材料B方案打分6/10，并建议检索是否有降低成本的方法。

主Agent读取批判和验证反馈后，决定采纳批判Agent建议：舍弃材料B方案，聚焦改良材料A实验。主Agent更新黑板上的最终方案列表仅保留材料A，并附加说明“材料A方案经过验证更具可行性”。**评估Agent**在任务结束后记录此次过程各Agent的表现指标（如文献Agent耗时、建模Agent准确性、批判Agent发现问题次数等），供系统开发者参考优化。最后，**报告生成Agent**读取最终方案和所有依据，在报告中生成对材料A合成实验方案的详细描述，包括步骤流程、创新点（参考了批判Agent点评）、可行性分析（参考了验证Agent的可行性检查）和参考文献列表（来自文献Agent输出）。报告Agent将此完整报告提交给用户。

上述交互流程展示了主Agent作为**调度者**如何发布任务并协调各Agent异步合作：信息获取和建模模块提供知识支撑，实验设计模块细化方案，验证和批判模块提供质量控制，最终经由主Agent汇总并由报告生成模块输出成果。

## 验证Agent

### 模块功能目标与边界定义

验证Agent的目标是**核实方案的可行性和一致性**。它侧重于检查各Agent提供的信息或假设是否**真实可靠**，以及不同来源/步骤之间有无矛盾之处。边界上，验证Agent不主动提出新创意或解决方案，也不负责全面审阅逻辑（这是批判Agent的职责）。它聚焦于**事实与约束的验证**，确保系统输出建立在可靠基础上。例如，验证Agent会检查：某实验方案所需资源是否现实存在，两个模型计算结果有无冲突，引用的文献数据是否吻合已知知识等。简而言之，验证Agent充当团队的“审计员”或“把关人”，边界限定在**发现明显错误和不可行之处**，不对方案进行创造性修改。

### 输入输出数据结构说明

* **输入：** 验证Agent持续**监听黑板**上由其他Agent写入的**关键输出**和**结论性内容**。典型输入包括：模型Agent的计算结论、实验设计Agent的方案草案、信息检索Agent提供的事实陈述、批判Agent的评论等。验证Agent对黑板输入的处理通常基于事件：例如\*\*“任务完成”**事件或**“方案草案生成”**事件出现时，它提取相关内容进行校验。也可能周期性扫描黑板上的新内容（如新的假设或数据）。输入的数据结构可以是：一个陈述/结果及其来源（例如“模型结果\:X=5”），或者一个完整方案草稿。验证Agent读取这些数据，将不同来源的信息关联比对，例如将**模型结果**与**文献数据**对照，或检查**方案所需条件\*\*与黑板上的资源列表。
* **输出：** 针对发现的问题，验证Agent会向黑板输出**验证反馈**事件。输出的数据结构通常是**警告或确认条目**，包含：引用被检验的信息片段、验证Agent的结论（通过/不通过/存疑），以及说明理由。例如：“⚠️验证警告：模型A预测结果与文献B数据不一致”或“✅验证通过：实验步骤符合安全规范”。这些输出通过在黑板发布**特定事件**来体现，如“冲突警告”事件、 “验证通过”事件等。验证Agent的输出格式需规范，便于主Agent或其他模块解析。例如可以采用 JSON 对象：`{"type": "验证反馈", "level": "警告", "detail": "发现假设X与已知事实Y冲突", "related_task": ID}`，或简单的文本标记格式。验证Agent通常不会修改其他Agent内容，而是**附加**自己的评估结果到黑板，以保持知识来源的透明可追溯。

### 与其他模块的协作机制与依赖关系

验证Agent与其他模块协作采用**异步监查模式**：它独立观察黑板，不直接与其他Agent通信，而是通过黑板的事件让主Agent和相关Agent感知问题。验证Agent依赖**信息获取Agent**和**建模Agent**提供的知识，因为其验证工作需要比较跨来源信息。它也依赖**实验设计Agent**的方案输出，以检查方案执行的可行性（材料、设备、条件是否合理）。反过来，**主Agent**依赖验证Agent提供可靠性信号，以决定是否需要调整计划（例如当验证Agent发出冲突警告时，主Agent会优先处理该事件）。**批判Agent**有时与验证Agent的功能略有重叠，但两者重点不同：验证Agent注重客观正确性和可行性检查，批判Agent注重逻辑和创新评审。协作上，当验证Agent发布警告后，批判Agent可能进一步分析此问题对整体方案的影响，或建议补充信息。验证Agent与**控制调度模块**的关系在于调度需要确保验证过程及时进行且不冲突：例如多个结果同时出现时，调度可安排验证Agent按优先级逐一检查，防止资源竞争。总的来说，验证Agent是**全局的把关角色**，为主Agent和其他模块提供可信赖的“第二道检验”，提升系统结果的可靠性。

### LLM提示词模板

验证Agent可以基于LLM实现复杂的**一致性检查**和**规则校验**。下面提供验证Agent的两个提示模板示例：

* **提示模板 1：信息一致性验证**

```text
系统: 你是科研助手中的验证Agent。现在需要检查以下信息是否存在冲突或不一致。
信息列表:
1. "{信息1内容}" (来源: {信息1来源})
2. "{信息2内容}" (来源: {信息2来源})
...
请逐对比较上述信息：
- 如果你发现两条或多条信息互相矛盾，指出矛盾之处并解释原因。
- 如果信息在逻辑或数据上不一致，也请指出。
- 若所有信息一致且无矛盾，回答“未发现矛盾”。
```

* **提示模板 2：方案可行性检查**

```text
系统: 你是科研创意系统的验证Agent，请评估以下实验方案的可行性并找出可能的问题。
实验方案草案:
"""{实验设计Agent提供的方案草案文本}"""
检查要求:
1. 确认方案所需的材料、设备是否现实可获得，条件是否可满足。
2. 判断实验步骤有无不合理或无法执行之处（如温度压力超出常规范围等）。
3. 核对方案假设与已知科学原理是否冲突。
4. 列出发现的问题或风险点；如无明显问题，则说明“方案在可行性方面未见明显问题”。
```

模板1引导LLM对多个事实性陈述进行**交叉验证**，可用于检测**信息检索结果**与**模型结果**是否矛盾等。模板2则针对一个完整方案进行**可行性审核**，从资源条件、执行步骤、科学原理等角度验证方案的现实操作性。这些Prompt利用LLM的知识和推理能力，帮助验证Agent智能地发现跨领域的不一致和不可行因素，提升系统输出的可靠性。

### 交互示例

**示例：** 黑板上已有模型Agent给出的结果：“材料A催化反应速率提升50%”，以及文献Agent提供的信息：“文献X报道材料A提升速率20%”。验证Agent监听到相关输出后，自动提取两者进行比较。通过内部LLM调用，它发现50% vs 20%存在矛盾，于是在黑板发布**冲突警告事件**：“⚠️验证警告：材料A的催化效率提升值存在矛盾——模型预测50%提升，但文献仅支持20%提升。”该事件包含引用模型Agent结果和文献Agent来源，以方便追溯。主Agent订阅了冲突警告，立即暂停推进后续任务，转而审视冲突原因。它可能指派批判Agent分析哪种说法更可信，或者请求信息获取Agent检索更多文献核实材料A的表现。最终，在验证Agent、批判Agent和信息Agent共同作用下，团队澄清了矛盾（可能是模型假设了理想条件，故结果偏高）。主Agent据此调整方案，例如降低对材料A性能预期或引入安全系数。

又例如，实验设计Agent在黑板提交了一份催化剂合成实验方案。验证Agent读取方案后，逐项检查：发现方案要求的反应温度为500℃，而文献资料显示该催化剂载体在400℃以上会失活。验证Agent据此发布**可行性问题**事件：“⚠️验证发现：实验步骤中的500℃高温可能导致催化剂载体失活（文献Y）。”这条反馈被黑板广播，实验设计Agent订阅相关提示后，可以自行修改方案（如果设计Agent具备根据反馈改进的功能），或者主Agent通知实验设计Agent调整条件。例如将温度降低到文献建议的范围内，或加入说明避免长时间高温。通过上述协作，验证Agent确保每个方案细节都经过**事实校验和现实检验**，把关系统输出质量。

## 批判Agent（Critic）

### 模块功能目标与边界定义

批判Agent的目标是对**阶段性成果和最终方案**进行审查、批评和改进建议，提升创意质量和可靠性。它相当于AI团队中的“审稿人”或“质询专家”，专门挑出方案中的问题和薄弱环节，并**提出改进方向**。批判Agent的作用边界在于**评审和建议**：它不会直接实施修改方案（修改由主Agent或相关Agent执行），也不会生成全新的独立方案（主Agent负责方案生成）。批判Agent聚焦于发现他人未发现的**逻辑漏洞、知识盲区、过度假设**等。例如，批判Agent会检查推理过程是否严谨，结论是否有充分依据，创意是否真有新颖性还是重复已有方案。边界上批判Agent不负责验证基础事实（验证Agent负责）也不执行具体领域任务，但它可能要求其他Agent去补充信息。当批判Agent存在时，系统形成一个**自我审阅循环**，在最终方案提交前进行“同行评议”，确保输出更完备。

### 输入输出数据结构说明

* **输入：** 批判Agent订阅黑板上**重要中间结果**和**最终方案草案**的事件。典型输入有：主Agent发布的任务解析和解题思路、各子Agent完成的里程碑结果（例如某子任务的结论）、实验设计Agent的完整方案草稿，以及验证Agent或其他Agent的反馈意见。尤其当黑板出现\*\*“方案草案生成”**事件时，表示一个可评审的整体方案已形成，这是批判Agent的主要切入点。批判Agent读取相关内容（通常是较大段的文本，如方案描述），并结合上下文知识进行评析。输入的数据结构可能是整合后的方案对象，包括方案条目（思路、步骤）、支撑证据列表、以及各Agent给出的结论汇总。批判Agent也可能参考**任务初始目标**和**评估指标\*\*作为输入，以对照检查方案是否满足目标、有哪些不足。
* **输出：** 批判Agent输出**评论和评分**形式的反馈到黑板。输出数据包括：批判意见文本、针对对象、严重程度和建议动作等。例如，一条批判Agent输出可能是：`{"type": "批判反馈", "target": "方案1", "comment": "缺少对副反应的考虑，可能低估了风险", "suggestion": "引入实验设计比较不同条件下副反应产率", "score": {"创新性": 7, "可行性": 6}}`. 其中**comment**是批判意见，**suggestion**给出改进建议，**score**（可选）对方案在某些维度打分。在文本形式时，批判Agent可能以段落评论附加一个建议列表和评分。批判Agent的输出通常在黑板显示为评论气泡或日志条目，与对应方案/任务关联。主Agent和相关子Agent可订阅\*\*“方案评审反馈”**事件，从而在批判Agent输出后做出响应（调整方案、追加任务等）。需要注意批判输出的**格式一致性\*\*，例如所有评分都在1-10区间并标注维度，所有建议均以清单列出，方便后续处理。

### 与其他模块的协作机制与依赖关系

批判Agent与**主Agent**高度协作：主Agent依赖批判Agent提供“第二观点”，在决策时参考其意见。批判Agent指出的问题会促使主Agent重新规划或调用额外任务（如批判指出文献支持不足，主Agent可能新建检索任务）。批判Agent也可直接对**信息获取Agent**或**建模Agent**的结果发表评论，要求更高证据支持或更严谨分析。与**验证Agent**的关系上，批判Agent更侧重高层次逻辑和质量，验证Agent偏重事实准确和可行性；两者经常串联工作：验证Agent发现具体矛盾，批判Agent进一步评估其对方案整体的影响并建议如何补救。批判Agent与**评估Agent**也有关联：批判Agent在每次任务中对方案评分，是对创意质量的即时度量；评估Agent则事后统计各Agent表现，二者关注点不同。批判Agent可能作为评估Agent输入的一部分（例如评估Agent将批判评分视为方案创新度指标的一环）。此外，在**控制调度**上，批判Agent输出通常被视为高优先级事件（例如**冲突警告**或**方案草案评审**事件)，调度模块会优先处理，确保批判反馈尽早纳入决策循环，不让系统在错误路径上走太远。依赖方面，批判Agent需要一定**领域知识**和**评审标准**（可由LLM的预训练知识和预设评价准则提供），也可能依赖外部知识库用于验证创新性。总而言之，批判Agent是系统内的**质量提升环节**，通过和各模块的紧密协作，形成自纠正闭环，提高方案的全面性和创新性。

### LLM提示词模板

批判Agent非常适合使用LLM进行方案审阅和评分。以下提供1-2个批判Agent调用LLM的提示模板：

* **提示模板 1：方案审阅与改进建议**

```text
系统: 你是科研创意系统的批判Agent，相当于评审专家。请对下面的方案进行审查并提出改进建议。
方案描述:
"""{完整方案或阶段性结果描述}"""
审查要求:
1. 分析方案的逻辑是否严密，指出推理中的漏洞或未证自明的假设。
2. 检查方案对目标的覆盖是否全面，有无明显的知识盲区或考虑不足的方面。
3. 评价方案的新颖性与创新点，判断是否只是已有思路的重复。
4. 针对发现的问题，每条给出具体改进建议。
输出格式:
- 列出发现的问题（用序号）。
- 对每个问题给出简短的改进建议或需要补充的工作。
如果方案整体良好，也请给出肯定意见和可能的进一步提升方向。
```

* **提示模板 2：方案评分**

```text
系统: 你是批判Agent，需要对不同方案进行评价评分，请阅读下列每个方案摘要并打分。
评价维度: 创新性、可行性、完备性（每项1-10分，10为最高）。
方案列表:
1. {方案A摘要}
2. {方案B摘要}
...
请针对每个方案：
- 先简单评价方案的优缺点。
- 然后按照创新性、可行性、完备性给出评分（格式如: 创新性=X, 可行性=Y, 完备性=Z）。
- 如果有特别突出的问题或亮点，附加说明。
```

模板1指导LLM以**审稿人**视角详细审查方案并给出改进建议，从逻辑、盲点、创新等方面确保方案质量。模板2则用于**定量评分**，按照预定义维度为方案打分，并可以结合模板1的分析作为依据。批判Agent通过这些Prompt调用LLM的强大评估能力，对AI生成的科研方案进行类似人类专家的评议，从而在系统内部建立**高标准的质量控制**机制。

### 交互示例

**示例：** 黑板上生成了两个备选实验方案：方案A（使用材料A，步骤较成熟）和方案B（使用新材料B，具有创新性但风险较高）。主Agent将这两个方案草案发布，触发**批判Agent**审阅。批判Agent读取方案A和B，通过LLM分析后，在黑板发布评论：

* 对方案A评论：“方案A步骤完整且基于成熟技术，但创新性一般。未考虑如果催化剂重复使用时活性下降的问题，建议补充相关测试。” 并给出评分例如“创新性=5，可行性=9，完备性=7”。
* 对方案B评论：“方案B有新颖的材料思路，然而对材料B可能存在的副反应缺少验证。风险较高，需要更多数据支持其可行性，建议增加小规模试验验证B材料的稳定性。” 评分例如“创新性=9，可行性=5，完备性=6”。

这些批判反馈以**批判反馈事件**形式写入黑板，主Agent收到后，参考评分认为方案A较稳妥但欠创新，方案B创新高但验证不足。主Agent可能决定综合两者优点：采用方案A的主体流程，同时引入批判Agent建议的小规模测试来评估材料B作为改进。主Agent据此修改最终方案，在黑板记录“方案A’（改进版）：加入针对材料B的小规模试验以探索创新性”。随后再次请求批判Agent复审改进后的方案A’。批判Agent这次给予较高评价：“方案A’兼顾了稳健性和创新探索，逻辑严谨。” 并更新评分“创新性=7，可行性=8，完备性=8”。主Agent据此将方案A’作为最终方案提交用户。

在整个过程中，批判Agent发挥了**审阅把关和指导改进**的作用。它批判性地审视AI生成的方案，使得方案在正式输出前经过类似**同行评议**的过程，多次打磨更加完善。这确保了系统给出的科研创意方案不仅正确可行，而且更具创新价值。

## 报告生成Agent

### 模块功能目标与边界定义

报告生成Agent的目标是将**黑板上最终方案和支撑论证**自动整理为**结构化报告**或清单，方便人类用户理解和使用。在边界上，报告生成Agent不参与方案内容的创造或评审，其职责是**信息整合与呈现**。它确保系统输出符合人类可读性要求，例如语言通顺、结构清晰、包含必要的背景和引用。报告Agent不会对方案本身做修改判断（除非格式需要），也不负责校验内容正确性（验证Agent/批判Agent已处理）。其作用类似秘书或技术写作助手，在输出边界内将AI团队成果编撰成文。

### 输入输出数据结构说明

* **输入：** 报告生成Agent在主Agent整合出最终方案列表并完成评分排序后启动。它从黑板读取**最终确认的方案**及其相关信息，包括：每个方案的描述、各模块提供的论据（如文献引用、模型结果摘要、实验步骤细节）、批判Agent的评分和评语、以及用户初始需求等背景材料。输入的数据结构可能是一个**方案列表对象**，其中每个方案条目含有标题、内容要点、评分、来源等字段。报告Agent也会参考黑板上记录的**推理链**日志，提取一些关键思考过程作为附录或说明（可选）。此外，如果有**模板**或**格式设定**（例如报告需要包含引言、方法、结果、结论章节），这些结构信息也作为输入参数提供给报告Agent。
* **输出：** 报告生成Agent输出**最终报告文档**或文本片段，通常写回黑板的报告区，或直接发送给用户界面。输出格式因应用而异：可能是纯文本Markdown，PDF报告，或HTML页面等。在黑板上记录时，可保存为带有标签的富文本（如Markdown) 以保留格式。内容上，报告包括：问题重述、解决方案摘要、多方案对比（如有多个方案则按评分排序列出）、每个方案的详细说明（来源依据、优劣分析）、最终推荐及其理由、以及引用资料列表等。报告生成Agent确保将黑板上的**结构化数据转化为连贯叙述**。例如，从方案对象生成文字：“**方案A**（评分8/10）：我们提出使用材料A...此方案基于文献\[1]和模拟结果\[2]，具有可行性高（验证Agent确认）且...”。输出的数据结构在黑板上可能标记为`{"type": "报告", "content": "...全文..."}`，或直接提供文件下载链接等。报告Agent还可能输出多种格式版本，如同时生成一份简要摘要供快速浏览。整个输出遵循人类可读的**报告规范**：分节段落、编号列表、引用标注等，使最终结果可作为科研笔记或提案文档使用。

### 与其他模块的协作机制与依赖关系

报告生成Agent与其他模块主要通过**黑板内容**发生协作，而不直接通信。它依赖**主Agent**提供确认的最终方案和要包含的要点信息。实际上，报告Agent通常在**所有其他Agent完成工作**并由主Agent整理出结果后才开始动作，因此它对之前模块都有隐含依赖（需要他们的输出）。**批判Agent**的意见和评分也是报告的重要组成部分，报告Agent会将这些内容融入对方案的评价描述中，例如注明“批判Agent评分”或引述其某条评论以增强说服力。报告Agent也利用**信息获取Agent**输出的参考文献数据，在报告引用部分列出来源，保证报告的学术规范性（这一点要求信息Agent输出带有文献信息）。**验证Agent**和**实验设计Agent**的细节输出会体现在报告的方案可行性分析和实验方法描述部分，由报告Agent整合成通顺段落。**控制调度模块**在报告生成阶段只需确保报告Agent可以安全读取黑板而不被干扰，通常报告生成属于最终阶段，调度上没有并发冲突问题。报告Agent与**评估Agent**一般没有直接协作关系，因为评估Agent的指标更多供系统内部优化，不一定出现在用户报告。不过在某些应用中，报告Agent也可附上一些过程评估信息（如AI信心度），这时可能参考评估Agent的数据。总的来说，报告生成Agent充当**终端整合角色**，在依赖所有前置模块结果的基础上，将**系统协作成果转化为用户可消费的知识产品**。

### LLM提示词模板

报告生成Agent可借助LLM来实现**语言生成与编排**。由于需生成较长结构化文档，可采用分段提示或few-shot范例提升质量。下面提供报告Agent的提示模板示例：

* **提示模板 1：报告正文生成**

```text
系统: 你是报告生成Agent，负责将AI团队的解决方案整理成人类可读报告。请根据提供的信息生成一份结构化报告。
提供的信息:
- 用户问题: "{用户的科研问题描述}"
- 方案列表:
  1. 方案A: 描述="{方案A描述}"; 依据={方案A支撑依据列表}; 评分={方案A评分}
  2. 方案B: 描述="{方案B描述}"; 依据={方案B支撑依据列表}; 评分={方案B评分}
- 批判Agent评审要点: "{批判Agent对方案的主要评价}"
- 关键背景知识: "{任何需要在引言交代的背景说明}"
写作要求:
1. 开头重述用户问题，说明本报告将给出方案比较。
2. 分别介绍每个方案：包括方案内容、为什么可行（引用支撑数据）、存在的不足或注意事项。
3. 引用批判Agent的意见和评分来客观评价每个方案。
4. 最后给出总结推荐，指出哪一个方案更优以及理由。
5. 使用正式的书面语气，结构清晰，有小标题或列表区分不同部分。包含引用标注以体现信息来源。
```

* **提示模板 2：方案要点摘要**（可选，用于生成简短结论或图表说明）

```text
系统: 你是报告Agent，需生成一个简短的方案对比摘要，方便快速阅读。
提供方案:
方案A: 优点="{简要优点}"; 缺点="{简要缺点}"; 评分={A评分}
方案B: 优点="{简要优点}"; 缺点="{简要缺点}"; 评分={B评分}
请以表格或项目符号方式列出每个方案的优缺点和评分，最后突出推荐方案。
```

模板1引导LLM根据黑板上汇总的信息**撰写完整报告**，强调结构和引用。它确保用户需求、方案细节、论据、评价和结论一应俱全，且语气和格式专业。模板2用于生成精简的**方案对比要点**，可以作为报告的摘要部分。通过这些模板，报告Agent能调用LLM将繁杂的多Agent输出转换为有条理的文字。例如，LLM会自动将多个Agent产出糅合成连贯段落，插入诸如“根据文献【1】…”的说法来引用信息Agent结果，或写到“批判Agent给予方案B高分主要因为…”。这极大减轻了人为整理负担，保证报告既**信息丰富**又**可读**。

### 交互示例

**示例：** 主Agent在黑板上最终确认了方案A’（改良后的材料A方案）作为输出，并保留方案B作为对比，附有评分和依据。报告生成Agent于是提取以下黑板内容作为输入：

* 用户问题：高效催化剂合成方案设计。
* 方案A’：描述为“使用材料A，加入预处理步骤提高重复使用寿命……”，依据包括“文献1支持材料A活性”、“模型结果显示可行”、“验证Agent确认可行性”，批判评分8/10等。
* 方案B：描述为“探索新材料B……”，依据有“文献2初步报道B效果”、“需要进一步实验验证”，批判评分6/10等。
* 批判Agent评语摘要：方案A’稳健可靠，方案B创新但高风险。
* 背景知识：催化剂评价标准、已有材料局限性等（来自信息Agent整理的背景）。

报告Agent调用LLM，生成报告框架：引言阐述问题和重要性；\*\*方案A’\*\*部分详细说明方案步骤、为何有效（引用文献1、模型数据），并提到批判Agent指出其可靠性高；**方案B**部分说明方案思路及创新之处，同时引用批判Agent意见强调其不确定性；**比较**部分对两方案进行优劣对比，表格列出评分；**结论**部分推荐方案A’为首选，因其兼顾效率与可行性，同时建议继续探索方案B的创新想法作为未来工作。报告末尾自动整理了引用文献列表，对应信息Agent提供的文献1、文献2等。生成的报告文字优雅专业，例如引言写道：“为实现高效催化剂合成，我们开发了两种候选方案。方案A’利用改进的材料A…；方案B引入新材料B…”，正文在介绍方案A’时包含“例如，DFT模拟结果显示材料A在300℃下稳定【2】”，结合模型Agent结果和文献引用。整个报告逻辑清晰、证据充分。主Agent审核报告后，将其发送给用户作为系统的最终输出。

通过报告生成Agent，复杂的多Agent协作成果被**转译为用户友好的呈现**。这让最终用户无需直接阅读黑板杂乱的中间记录，也不必手动整理各方面信息，就能获得一份完整的科研方案提案。报告Agent确保最后一步输出专业且易读，为多Agent系统画上圆满句号。

## 实验设计Agent

### 模块功能目标与边界定义

实验设计Agent的目标是将概念层面的科研创意或方案，转化为**具体可执行的实验流程**。当系统提出了新的理论假设或方案思路后，实验设计Agent细化出**实验方法**，包括步骤流程、材料与设备清单、参数设置和观察指标等。它充当团队中的“实验专家”，确保创意不仅停留在想法层面，而且有落实为实际试验的路径。边界上，实验设计Agent不决定假设是否有价值（那是主Agent和批判Agent的任务），也不评价实验意义（评估Agent可能关注成果意义）。它专注于**方案落地**：比如如果创意是新催化剂材料，实验设计Agent会设计合成该材料的具体步骤和测试其性能的实验方案。它不会介入与实验无关的推理环节，也不执行实验（仅设计）。在团队边界划分中，实验设计Agent保证每个想法**有可能被验证**，防止系统输出停留在纸上谈兵的阶段。

### 输入输出数据结构说明

* **输入：** 实验设计Agent关注**黑板上出现的方案概要或待设计实验的提示**。典型的触发输入是主Agent发布的子任务如“设计实验步骤”，或者黑板上出现一个**方案骨架**需要具体化。例如，当黑板上有“候选方案：假设X可提高性能，需要实验验证”时，实验设计Agent就会介入。输入的数据包括：方案的背景和目标（如要验证假设X）、已有的理论支持（来自信息Agent或模型Agent的结论），以及实验设计的要求（可能由主Agent在任务描述中给出，例如“要求不使用某些有害试剂”）。数据结构可以是一个**实验任务描述**对象，例如：`{"task": "实验设计", "target": "验证催化剂A性能", "constraints": ["设备: 常规实验室可用", "测量: 转化率"]}`。实验设计Agent利用这些信息，连同自身领域知识，作为制定实验方案的依据。如果有多个方案需要实验，实验设计Agent可能分别生成设计，或者主Agent按优先级提供一个方案进行设计一次。
* **输出：** 实验设计Agent输出**实验方案草案**，写入黑板供团队讨论。输出格式通常是结构化文本，包含分步骤的实验流程和相关要素说明。例如：

  * 实验目标：简述实验要验证的假设或测量的性能指标。
  * 材料与设备：列出所需化学品、仪器装置及其规格。
  * 实验步骤：序号列出每一步骤的操作（配制、反应条件、测量方法等）。
  * 数据收集与分析：说明需要记录的数据及后续分析方法。
  * 安全及注意事项：列出实验可能的风险及相应防范措施。
    这种输出可采用Markdown清单或段落形式，以清晰呈现。黑板中可以将其标记为`{"type": "实验方案", "content": "...详细文本..."}`或者分段存储在多个条目下。实验设计Agent可能还输出**实验方案结构化数据**（如JSON包含步骤和材料字段），供验证Agent检查可行性或报告Agent引用。在多人协同下，一个Agent的实验方案输出，往往会被验证Agent和批判Agent读取审核，因此需保证**格式清晰、语义准确**，方便他们逐项检视。

### 与其他模块的协作机制与依赖关系

实验设计Agent主要在**方案形成的中后期**与其他模块发生交互。它依赖**主Agent**提供需要设计实验的明确目标。例如主Agent在任务分解时明确提出“设计实验验证X”子任务，这就是实验设计Agent工作的起点。实验设计Agent也需要**信息获取Agent**和**建模Agent**提供的上下文知识：文献中已有的实验方法、模型预测的参数范围等，这些信息会影响实验方案设计的合理性。**验证Agent**与实验设计Agent协作紧密：当实验方案草案生成后，验证Agent会检查其中的可行性问题。如果验证Agent指出某材料不易获取或步骤不合规，实验设计Agent需根据反馈进行修改。**批判Agent**也会对实验方案进行审视，尤其关注方案是否充分验证了假设、是否遗漏关键对照实验等建议。实验设计Agent在接收到批判Agent的改进建议后，可以修正或扩展实验方案（例如增加对照组实验）。**控制调度模块**会确保实验设计Agent在适当的时机启动（通常在理论方案有了一定雏形之后），且当实验方案未定稿前，不进入最终报告阶段。实验设计Agent不直接互动**评估Agent**，但其输出成功与否可从验证Agent和批判Agent的反馈中体现，评估Agent可能统计实验方案被修改次数作为其绩效指标之一。总之，实验设计Agent与知识/模型类Agent**前后相依**：前期获取知识支持、后期接受验证批判，确保创意走完从理论到实践设计的闭环。

### LLM提示词模板

实验设计Agent可借助LLM的知识和推理能力来自动生成合理的实验方案。以下提供提示模板示例：

* **提示模板 1：实验方案生成**

```text
系统: 你是实验设计Agent。请根据给定的研究假设和目标，设计一个具体的实验方案。
背景假设/目标: "{需要验证或实现的假设/目标描述}"
已有信息:
- 理论支持: "{相关理论或模型结论，如某材料预测具备某性能}"
- 已有条件: "{实验可用的资源或设备限制，如现有仪器型号}"
设计要求:
1. 明确实验目的和将测量的指标。
2. 列出所需的材料和设备。
3. 详细规划实验步骤（包括参数如温度、时间等）。
4. 指定将如何收集和分析数据以验证假设。
5. 提及实验中的安全或合规注意事项。
请用清单方式给出实验方案各部分。
```

* **提示模板 2：实验方案改进**（根据反馈调整方案）

```text
系统: 你是实验设计Agent。以下是初步拟定的实验方案及专家反馈，请据此改进方案。
初步方案:
"""{实验方案草案文本}"""
反馈意见:
"{验证Agent/批判Agent的具体意见，如材料B难以获得，需替换; 缺少对照实验等}"
改进要求:
- 针对反馈修改方案步骤或材料选择，保证方案可执行且全面验证假设。
- 保留原方案有效部分，补充缺失部分。
输出最终修正后的完整实验方案（格式同上）。
```

模板1让LLM基于假设和上下文**生成初版实验方案**，确保包含关键要素并结构清晰。模板2用于当收到验证/批判反馈后，对方案进行**定向修改**，如更换不可行的部分、增加对照试验等，使方案更完善可行。这两个Prompt结合使用，可以模拟人类实验设计的过程：先有一个方案，然后根据评审意见迭代改进。LLM强大的知识库能够帮助填补细节（如知道常用仪器、典型实验流程），尤其在科研领域实验设计需要相当专业知识时，可通过大模型获取。实验设计Agent应用这些模板，可以快速地产生高质量的实验方案文档，并根据团队反馈做出调整。

### 交互示例

**示例：** 系统在研究一种新催化剂材料的理论可行性后，主Agent添加任务：“设计验证该催化剂性能的实验”。实验设计Agent读取黑板相关内容：材料性质预测（来自建模Agent）、文献参考的类似实验方法（来自信息Agent），以及主Agent对实验目标的描述（例如提高产率的目标指标）。实验设计Agent通过LLM生成实验方案草案，包括：

* **目的：** 测试新催化剂材料A在典型反应中的活性和稳定性，与商用催化剂对比。
* **材料：** 列出材料A制备所需前驱物、对照催化剂B、溶剂、试剂等；设备如反应釜、色谱仪。
* **步骤：** 1）合成材料A（给出化学步骤和条件）；2）在固定条件下用材料A进行反应测试（温度、压力、时间参数）；3）用相同条件用催化剂B测试；4）通过色谱分析产物计算产率等；5）循环多次评估材料A的重复使用性能。
* **数据分析：** 记录每次反应的产率和选择性，与对照比较；分析材料A活性随循环次数的变化。
* **注意事项：** 提醒该反应需在无水氧条件下操作，材料A可能有纳米颗粒需谨慎处理等安全事项。

该方案发布到黑板。**验证Agent**随后检查方案：发现材料A合成步骤需要的某种前驱物X剧毒且实验室无法采购（可行性问题）。它发布警告：“前驱物X危险且难获，建议替换原料”。**批判Agent**也评论：“方案缺少空白对照实验（没有催化剂的基线反应）”。实验设计Agent读取这些反馈后，启动改进：参考文献找替代前驱物Y（虽产率稍低但安全易得），并在步骤中增加一条“进行无催化剂的对照实验以测定空白反应速率”。修改后的方案重新写入黑板。验证Agent二次检查通过，批判Agent也认可方案完善。

最终，这份完善的实验方案由报告生成Agent纳入最终报告。在报告中，实验方案部分清晰列出了上述内容，使读者明白如何在实际中验证系统提出的创意想法。通过实验设计Agent的作用，每个抽象的科研创意**都有具体实验支持**，增强了方案的可信度和可操作性。

## 控制调度模块（Control Shell/Scheduler）

### 模块功能目标与边界定义

控制调度模块负责整个多Agent系统的**流程控制与资源调度**。其目标是在黑板协作环境下，防止混乱并**提高并发效率**，充当多个Agent并行工作的“主持人”和“仲裁者”。具体功能包括：监视黑板上的任务与事件队列，根据优先级选择下一步由哪个Agent执行；协调多个Agent同时读写黑板，避免冲突；当出现异常或冲突事件时，决定处理策略（如暂停某些任务、引入批判Agent解决矛盾）；以及在Agent空闲时触发新任务，确保计算资源充分利用。边界上，控制调度模块不参与具体学术内容推理，也不产生领域结果，其职责是**流程管理**。在实现上，它可以由主Agent担任（主Agent内部实现调度逻辑）或独立的模块运行。我们在此将其视为独立模块，以突出调度功能设计。控制调度模块的边界不涉及修改任务本身（由主Agent规划），也不决定任务优先级规则（由系统预先设定或主Agent调整），它执行的是既定策略下的调度和控制。

### 输入输出数据结构说明

* **输入：** 控制调度模块的输入主要来自**黑板事件队列**和**Agent状态信息**。黑板会维护一个**待处理事件/任务列表**，每个事件含有属性：事件类型、关联任务ID或数据、优先级、时间戳等。例如：`{"event_id": 101, "type": "任务发布", "task": {"id":1, "type":"信息检索", ...}, "priority": 0.8}`。调度模块持续监听该队列。当有**Agent空闲**且有待处理事件时，它选择合适事件进行分配。另一个输入是**当前各Agent状态**（忙/空闲、运行中的任务等），以避免将任务指派给忙碌Agent。调度模块还监视**黑板锁/版本**信息，当Agent试图写入黑板时作为输入以检测并发冲突（例如同一条目被两个Agent同时修改）。
* **输出：** 控制调度模块的输出包括：**Agent调用指令**和**黑板控制信号**。对每个选定的事件任务，它输出指令触发对应类型的Agent执行。例如通过内部API调用`trigger_agent(agent_type="信息检索", parameters={...})`，或者在黑板上设置任务状态为“进行中”，让Agent自检到被选中执行。另外，调度模块可能输出**黑板锁定/解锁**标记，例如当某Agent正在写入特定黑板段时，标记该段上锁以防他人写入。遇到Agent冲突或异常，调度模块输出**协调决策**：比如产生一个冲突解决事件（由批判Agent或主Agent处理），或记录某Agent超时未响应并重派任务给备选Agent。许多调度模块的输出是对系统内部状态的更新，而非黑板上新增内容。然而为了透明和可调试，某些调度动作也可以记录到黑板日志。例如：`{"type":"调度日志", "message":"已将任务2指派给建模Agent", "timestamp":...}`，供开发者或评估Agent事后分析。总的来说，调度模块输出的核心是**任务分配决策**和**冲突仲裁结果**，通过内部调用或黑板标记实现，不直接产生科研内容。

### 与其他模块的协作机制与依赖关系

控制调度模块与所有Agent都有关系，因为它掌控着**谁在何时执行何任务**。特别地：

* 与**主Agent**：主Agent制定任务和优先级策略，调度模块据此执行调配，相当于主Agent的执行助手。主Agent也可兼任调度功能，在此情况下无需独立模块，但如果独立，主Agent需向调度模块提供当前任务优先级或特殊调度规则，比如“任务A完成前暂停任务B”之类。
* 与**信息/建模/验证/批判/实验设计Agent**等：调度模块监视这些Agent的状态，确保不要同时调度冲突任务。例如，如果验证Agent和批判Agent都对“方案草案”事件有反应，调度可决定先让验证Agent运行完，再让批判Agent评审，避免二者同时评论导致混乱（当然也可并行，这取决于策略）。再如**信息获取Agent**任务往往可并行执行，调度模块在任务发布时可一次性激活多个不同的信息Agent并行检索不同子问题，以加快进度。
* 与**评估Agent**：评估Agent可能提供关于Agent性能的反馈（如某Agent慢或错误多），调度模块可以依赖这些反馈优化调度决策。例如降低不可靠Agent的任务分配频率，或当高优先任务需要高成功率时指派给历史绩优Agent执行。
* 与**黑板系统**：调度模块和黑板关系最密切。它依赖黑板队列来获取任务事件，亦通过黑板实现互斥和同步。调度模块必须确保对黑板的更新是**原子**的，例如取任务时标记状态，以免多个调度实例重复调同一任务。黑板中的**事件优先级**规则和**订阅列表**需要与调度模块配合良好：订阅机制决定哪些事件引起哪些Agent响应，而调度模块决定具体时序顺序。两者协同确保系统按设计策略运行。

控制调度模块是整个系统正常运转的**保障组件**，高度依赖于正确配置的规则和各Agent状态信息。其他模块从逻辑上需要遵守调度模块的安排（例如Agent只有在被激活或在检测到相关黑板事件时才行动），因此可以说所有Agent都间接依赖调度模块维持秩序。良好的调度避免资源浪费和竞态，提高系统效率和稳定性。

### LLM提示词模板

一般来说，控制调度模块主要以硬编码逻辑或简单规则实现，不直接调用LLM完成任务调度。但在某些复杂决策场景，可以借助LLM进行调度优化或策略选择。例如，当有多个冲突解决方案时，让LLM评估哪种更合适。以下提供一个可选的提示模板示例，以展示LLM在调度决策中的辅助作用：

* **提示模板示例：冲突决策辅助**

```text
系统: 作为科研多Agent系统的调度模块，你刚检测到一个冲突事件。
冲突描述: "{验证Agent给出的冲突描述，例如“模型结果与文献结论不一致”}"
当前进展:
- 正在运行的任务: {列出}
- 等待中的任务: {列出}
请根据以上信息，决定调度策略：
1. 哪个Agent应首先处理该冲突（例如批判Agent分析原因，或主Agent重新规划）。
2. 是否需要暂停其它相关任务直至冲突解决。
3. 后续任务顺序是否调整。
请给出决策步骤和简要理由。
```

该模板让LLM基于当前冲突类型和任务状态**建议调度决策**，如优先调用批判Agent解决矛盾。尽管实际实现中可能以预设规则直接处理（例如所有冲突事件始终触发批判Agent优先处理），但在更复杂情境下LLM可以综合上下文给出柔性决策。这只是辅助手段：理想情况下调度模块的大部分决策在设计阶段已定策略并编码。然而如果需要**自适应调度**，LLM Prompt可帮助调度模块做出更智能的决定，例如在系统繁忙时调整并发数，或在资源冲突时学会优化执行顺序。

### 交互示例

**示例：** 黑板的事件队列当前包含数个事件：`E1: 文献检索任务完成`、`E2: 模型计算任务完成`、`E3: 冲突警告（验证Agent报告矛盾）`，以及`E4: 新的批判反馈`。控制调度模块根据优先级规则，发现`E3: 冲突警告`是高优事件（因为涉及方案正确性）。此时：

* 调度模块暂停触发与冲突相关的进一步任务，例如暂缓新的实验设计任务，防止基于可能错误的前提继续推进。
* 调度模块检查**批判Agent**空闲，于是立即指派批判Agent处理冲突事件（让批判Agent深入分析冲突并提供裁定)。批判Agent因此被触发，读取冲突细节展开工作。
* 在批判Agent处理期间，调度模块避免其他Agent对相关内容的修改（可通过黑板锁定相关方案条目实现），但对于无关的并行任务（比如另一个独立子问题的检索任务）则可继续调度，以不浪费并行能力。
* 批判Agent完成后，在黑板发布了冲突分析结果（例如确定哪个信息可信，或建议进一步实验求证）。
* 调度模块收到批判Agent完成事件，将锁定解除。接着，它通知**主Agent**（可能通过事件或直接调用）更新全局计划。主Agent根据批判结果调整方案，发布新的任务或取消一些任务。
* 然后调度模块按照更新后的任务列表继续分配后续任务执行，比如现在可以恢复暂停的实验设计任务（若冲突已解决或方案修改完毕）。

在另一情境下，假如有两个普通信息检索任务`E5`和`E6`同时待处理，而系统有多个文献Agent可并行，调度模块可以**并行激活**两个文献Agent各自执行任务E5和E6。这利用了多Agent的并行优势，加快信息收集速度。如果其中一个Agent执行过慢，调度模块监测到其超时，则可取消该任务并改派另一Agent重试，或者降低其优先级。这些都由调度模块根据设定策略自动处理，无需人工介入。

通过上述机制，控制调度模块确保多Agent协作既**高效并行**又**有序可控**。无论是高优先级事件的及时处理，还是常规任务的负载均衡，调度模块的存在让系统能够在复杂交互中保持稳定运行。例如，在Anthropic的多Agent研究系统中，就采用了类似**主从调度架构**保证LeadAgent和Subagent协调工作。本方案的调度模块正是发挥这样的幕后作用，使各智能Agent在黑板上**各司其职、互不抢占**，实现整体协同优化。

## 评估Agent

### 模块功能目标与边界定义

评估Agent的目标是对**系统自身的表现**进行评估和反馈，帮助系统**持续优化**。它主要承担两方面评估：

1. **对每次任务过程中各Agent的性能进行评价**（效率、准确性、协作度等），并对最终产生的创意方案质量进行整体评估。
2. **收集长期数据**，用于改进Agent提示词、调度策略或替换模型，以实现系统自我进化。

边界上，评估Agent不参与当次任务解决过程的具体内容产出，也不干预任务流程（除非作为反馈提出改进建议）。它主要在**任务结束后或特定评估点**介入，对整个过程做元分析。评估Agent不会影响当次结果呈现给用户的内容（报告Agent完成后再评估），其作用体现在**系统内部循环**：为开发者或主Agent提供优化依据。可以将评估Agent类比为团队的“绩效考核者”或“导师”，帮助AI团队越来越默契高效。边界方面，它不会更改黑板上的领域知识内容，也不定义评价指标（指标体系应由开发者预设），只负责执行评价。

### 输入输出数据结构说明

* **输入：** 评估Agent在每轮任务完成或定期触发时，收集**大量过程数据**作为输入。主要输入包括：

  * **黑板交互日志：** 所有黑板事件记录（时间戳、事件类型、内容概要）、各Agent的输出内容日志。
  * **性能指标数据：** 自动记录的如每个Agent响应时间、使用的计算资源消耗、错误和冲突次数等。
  * **结果质量数据：** 最终方案数量及其评分、用户对结果的反馈（如果有人工反馈）。
  * **Agent互评信息：** 批判Agent对各Agent的评语、评分Agent（如有）给出的评价等。

  输入数据结构可以很复杂，可能整理为多个表格或JSON：例如每个Agent一个记录，包含{name: "文献Agent", tasks\_completed: 3, avg\_time: 15s, errors: 0, ...}；每个方案一个记录，包含{score: ..., novelty: ..., issues: ...}等。评估Agent需将这些离散数据汇总分析。为了智能分析，评估Agent也可将部分输入转化为**自然语言描述**，比如“文献Agent在任务1耗时60秒，任务2耗时55秒，提供的信息有2处被验证Agent标记冗余”。这类描述可供LLM直接阅读评估。
* **输出：** 评估Agent输出两类结果：

  1. **即时反馈：** 在检测到明显问题时，生成针对特定Agent或系统的反馈提示。例如：“⚠️效率警告：建模Agent平均用时过长，建议优化算法或提示” 或 “协作提示：信息Agent提供重复内容，需改进去重逻辑”。即时反馈可以写入黑板或日志供主Agent和开发者参考，甚至可以在下一个任务开始前调整参数。例如黑板事件`{"type": "评估反馈", "agent": "建模Agent", "issue": "慢", "recommendation": "改进模型或降低并发"}`。
  2. **定期报告：** 经过每轮任务后，评估Agent生成**综合评估报告**，记录各Agent表现评分和系统整体表现。这报告可供开发人员线下查看，或供主Agent在随后的运行中调整决策。内容包括：各Agent本轮得分（效率、准确性、协作等维度），具体数据支撑（如响应时间列表）、本轮出现的主要问题汇总、优化建议清单（如调整Prompt、替换某Agent、增加某方面知识）。输出格式可以是结构化日志文件、数据库记录，或黑板上的长文本条目标记为“评估总结”。开发者可以为评估报告设计固定格式，方便比对，比如CSV行：AgentName, EfficiencyScore, QualityScore, Notes。

评估Agent的输出绝大部分供**内部使用**，并不直接呈现给终端用户。但在系统界面上可以开放一个开发者视图，显示评估Agent的报告，帮助改进系统。因此其输出在黑板或日志中也需要清晰易读。

### 与其他模块的协作机制与依赖关系

评估Agent在体系中扮演**元分析者**角色，与其他模块的关系主要体现在提供改进反馈和利用他们的互评数据：

* **与主Agent：** 主Agent可以在任务结束后调用评估Agent来获取本次协作的评分和改进建议。主Agent也可能部分地自动采取评估建议，例如降低某Agent调用频率、在下次计划时冗余分配任务以防单点失败。主Agent和评估Agent一起形成系统的**自适应调节**机制。
* **与批判Agent：** 批判Agent在每轮中对方案或Agent表现的批评实际上构成了一种“互评”。评估Agent会收集批判Agent对各部分的评论，将其作为对那些模块的表现评价。例如批判Agent指出“信息Agent提供资料有遗漏”，评估Agent记录信息Agent在“完整性”上扣分。两者协作使评估更全面，结合AI自己对自己的评价与中心评估相印证。
* **与控制调度模块：** 评估Agent可能提供关于并发和调度的反馈，如发现系统长时间空闲或某类任务拥堵，则建议优化调度策略。调度模块本身不智能调整策略，但主Agent或开发者可以根据评估Agent报告修改调度策略配置。
* **与各子Agent：** 评估Agent通过日志了解每个Agent的行为，对于持续表现不佳的Agent，评估Agent会建议替换或优化。例如，如果**建模Agent**频繁出错，评估Agent报告可以提示开发者尝试更好的模型（换用更强大的API）。对于LLM驱动的Agent，评估Agent也可能建议**Prompt优化**：利用LLM帮助改写那些经常误解任务的Agent提示词，使其职责和输出要求更明确。评估Agent本身不去改代码或Prompt，但可触发\*\*“Prompt优化Agent”\*\*或记录建议供开发者处理。
* **与信息获取/建模Agent：** 评估Agent间接依赖这些Agent在过程中标记的信息正确与否，以便计分。例如如果建模Agent的结果后来被验证Agent判定错误，那评估Agent会给建模Agent准确性差的评价。反过来，信息和建模Agent不直接使用评估Agent输出，但**长期**上，如果系统可以自进化，主Agent可能在启动下一次任务前参考评估结果调整对这些Agent的调用策略，这种作用也是通过评估Agent实现的。

综上，评估Agent是一个贯穿系统生命周期的**优化环节**。它依赖其他模块提供原始数据，又反过来影响其他模块未来的工作方式。没有评估Agent，系统只能盲目重复；有了评估Agent的反馈闭环，系统可逐步减少错误、提高效率，朝着更优协作状态演进。

### LLM提示词模板

评估Agent的分析可以部分通过LLM来完成，特别是对于**定性指标**（如协作度、创新度）的判断。以下给出提示模板示例：

* **提示模板 1：日志分析与评分**

```text
系统: 你是评估Agent，下面是一段多Agent系统本轮运行日志及数据，请根据其中的信息对各Agent表现评分并总结问题。
日志片段:
"""{黑板事件和对话日志摘录，例如:
- 文献Agent: 完成任务1, 用时45秒.
- 建模Agent: 完成任务2, 用时120秒, 结果与验证Agent反馈不一致.
- 批判Agent: 指出方案缺少环境影响考虑.
- ...}"""
性能数据:
- 文献Agent: 完成2个任务, 平均用时47.5秒, 错误0次.
- 建模Agent: 完成1个任务, 用时120秒, 1次结果不可靠.
- 批判Agent: 提出3条意见, 解决2个问题.
评估要求:
1. 根据效率、准确性、协作度等对每个Agent评分（1-10）并解释原因。
2. 指出本轮出现的主要问题（例如哪个Agent成为瓶颈，哪方面信息不足）。
3. 给出改进建议，如哪些Agent需要优化及如何优化。
格式:
- Agent表现评分:
  - 文献Agent: 效率=__, 准确性=__, 协作度=__, 评语:__.
  - 建模Agent: 效率=__, 准确性=__, 协作度=__, 评语:__.
  ...(每个Agent)
- 总体问题: ... (列出)
- 改进建议: ... (列出)
```

* **提示模板 2：方案质量评估** (可选，用于结合用户反馈或结果创新性评价)

```text
系统: 你是评估Agent，请评价本轮最终输出的创意方案质量。
最终方案列表及评分:
"""{方案列表，包含批判Agent评分和方案简介}"""
评价要求:
- 整体满足用户需求的程度（1-10）？
- 创新性如何？相比已有方案有何突破？
- 有无明显遗漏或不当之处？
- 综合以上给出对系统本轮输出的满意度评分，以及需改进的方向。
```

模板1将**运行日志和量化数据**提供给LLM，请其生成对每个Agent的表现评估和改进建议。这相当于让LLM充当一个\`\`分析助手''，替开发者从繁杂日志中提炼关键信息。模板2针对**方案质量**进行评估，可用于汇总批判Agent等已有评价，再让LLM给出全局视角的评分，比如“本轮方案整体创新性8分，但在环境影响考虑上有所欠缺”。评估Agent使用这些Prompt，可以将大量原始数据转化为**可读报告**和**具体建议**。最终这些建议会反馈回系统设计人员或者主Agent策略模块，驱动Prompt优化、模型替换、知识更新等后续动作。

### 交互示例

**示例：** 一轮任务完成后，评估Agent启动对本轮过程的评估。它收集到的信息包括：文献Agent检索用了多次查询耗时较久、建模Agent的结果被验证Agent判为不可靠一次、批判Agent提出了关键改进使方案大幅优化等。评估Agent将这些编入日志摘要并运行提示模板1的LLM分析。LLM输出如下评估：

* 文献Agent: 效率=6/10（检索有点慢），准确性=9/10（提供资料无错误），协作度=8/10（结果格式清晰有引用）。评语：需提升检索速度，可能通过并行查询改进。
* 建模Agent: 效率=7/10（用时适中），准确性=5/10（有1次重要错误结果），协作度=7/10（结果有说明但误导了后续流程）。评语：模型可靠性不足，应改进模型参数或方法。
* 验证Agent: 效率=8/10（及时发现问题），准确性=10/10（指出矛盾正确有效），协作度=9/10（有效防止错误传播）。评语：表现优秀，继续保持。
* 批判Agent: 效率=9/10（实时给出反馈），准确性=9/10（建议有价值），协作度=10/10（提升方案质量显著）。评语：发挥了重要peer review作用。

总体问题: 建模Agent的一次错误导致流程反复，需要提高模型结果可靠性或增加冗余检验；信息检索稍慢影响总体效率。
改进建议:

1. 尝试升级建模Agent模型或增加二次验证环节；
2. 优化文献Agent检索并行度；
3. 保持批判/验证Agent的强交互，多Agent互评机制证明有效，应继续强化。

评估Agent将此报告写入系统日志，并通知主Agent。主Agent据此在下一次任务规划时调整：例如对于关键计算任务，引入**双模型冗余**（两个建模Agent并行计算取较可信结果），或者提高文献Agent线程数。开发团队收到报告后，也考虑替换建模Agent所用的模型库，以降低错误率。在后续版本中，Prompt工程师还依据评估Agent多次报告中批判Agent的反馈，调整了各Agent的提示词，使角色指令更清晰（防止误解任务）。

在另一层面，评估Agent通过长期收集数据，可能发现某类任务一贯地由某个Agent完成质量最高。比如多次任务显示“文献Agent A结果丰富度远超Agent B”，于是评估Agent建议在将来**默认使用Agent A**执行文献检索以提高效率。系统开发者采用此建议，更新了调度配置，系统协作性能因此提升。

通过评估Agent的周期性介入，整个多Agent系统形成了**评价-反馈-改进**的闭环。每轮任务的经验（成功与不足）都会沉淀为数据，推动系统在Prompt、策略、模型上的优化。久而久之，系统的创新质量和执行效率都会越来越好。这种自我进化特性是多Agent架构的一大优势，而评估Agent正是这一机制的核心驱动。

## 系统整合与协同架构

上述各核心模块在系统架构中通过**黑板机制**和**任务调度**无缝融合，并与信息获取Agent、建模Agent共同协作，形成闭环的科研创意生产流程。整体上，**主Agent**作为中枢，利用黑板发布任务给**信息获取Agent**和**建模Agent**获取知识和模型结果，再协调**验证Agent**检查这些结果的可靠性、由**实验设计Agent**将概念转化为可执行方案，邀请**批判Agent**对方案进行评审改进，最终调用**报告生成Agent**输出成果文档，并通过**评估Agent**对过程进行反思优化。这些模块各司其职又相互依赖，使系统运作如同一个有序的科研团队。

具体协同逻辑如下：

* **融合信息获取和建模Agent：** 主Agent将检索类、计算类子任务指派给信息获取Agent和建模Agent执行，由它们提供文献调研结果和模型分析结果作为**方案依据**写入黑板。验证Agent会并行监控这些结果，一旦发现信息和模型结论之间冲突或疑点，立即通过黑板发出**冲突警告**。控制调度模块捕获到冲突事件后，会优先暂停相关后续任务，调度批判Agent分析矛盾原因或请求进一步信息，使冲突在扩散前被解决。例如，信息Agent检索到材料A文献结论与建模Agent模拟预测不符，验证Agent提示这一冲突，批判Agent评估后建议基于文献修正模型假设或获取更多数据。主Agent据此可能再调用信息Agent补充检索或令建模Agent重新计算，直到冲突消除。这样，信息获取Agent、建模Agent的产出通过验证Agent和批判Agent的中介，与核心模块形成**闭环验证**：既丰富了创意方案的信息深度，又确保可靠性得到跨检验。整个过程中，黑板作为共享内存承载所有这一切，使**知识获取**（信息Agent）、**理论推演**（建模Agent）和**智能决策**（主/验证/批判等Agent）充分融合在一起。

* **模块协同的流程控制：** 控制调度模块保障各Agent的协同有条不紊。它按照主Agent规划的并行/串行策略执行任务调度：独立的检索和计算任务由调度器并行分配给多个Agent执行，以缩短总耗时；而有依赖关系的任务（如必须先有模型结果才能设计实验）则由调度器强制顺序化。调度模块也统一管理**事件优先级**：如当批判Agent发出重要的方案缺陷反馈事件，调度立即让主Agent停下来处理反馈，避免错误方案进入下步。对于黑板并发写入，调度模块通过锁或版本控制防止冲突，并在检测到**资源冲突**（如两个Agent同时改同一条目）时触发冲突事件交由批判/主Agent解决。因此，在协同逻辑上，调度模块保证**先后次序合理**和**互斥访问安全**，让信息获取Agent、建模Agent等与核心智能模块的交互可以**无死锁、无竞态**地进行。可以说，调度模块是各Agent协同工作的粘合剂和交通警察。

* **最终方案汇总与输出：** 当所有必要的知识检索和模型分析完成后，主Agent汇总黑板上的部分成果，得到初步方案集合。此时，**实验设计Agent**和**批判Agent**发挥作用：实验设计Agent依据方案集合完善实验细节，使每个方案都**可实际实施**；批判Agent则针对每个方案的优劣进行**评分和评论**。主Agent收集批判Agent评分，将其与自身判断结合，对方案列表进行**排序筛选**，可能剔除一些低评分方案。这里也可引入专门的**评估Agent**或让批判Agent协助多维度评分，确保排序综合考虑创新性、可行性等因素。在最终方案确定后，报告生成Agent读取黑板上的**方案列表、批判评分、依据材料**等，编排生成用户报告。报告Agent确保信息获取Agent提供的**引用**得到妥善引用，建模Agent的**关键数据**写入结果分析，验证Agent和批判Agent的**结论**融入讨论，从而在报告中给出令人信服的完整论证链。整个汇总过程体现了**各模块成果的融合**：没有信息Agent的文献，方案缺乏背景；没有建模Agent的数据，论证无定量支撑；没有验证/批判Agent把关，方案可靠性和质量无法保证。只有集成各方所长，系统才能输出高质量的科研创意方案合集。

* **闭环反馈与持续优化：** 最后，在用户得到报告之后，评估Agent登场对这一轮流程进行检视，将关键统计和改进建议反馈给系统开发和下轮运行调整。例如，如果评估Agent发现某次任务中信息获取Agent耗时过久，它会记录建议加强资料库索引或并发度；发现某批判Agent的反馈多次被忽视导致反复，建议主Agent提高对批判事件的优先级。这些优化建议通过开发者调整或主Agent下次加载配置时应用，从架构层面实现**自适应调整**。评估Agent甚至可以推动**Prompt自动优化**：如多次任务后发现实验设计Agent经常遗漏对照组，则修改其Prompt模板加入要求。通过这种反馈学习机制，信息获取Agent和建模Agent也逐步被使用在**最恰当的时机**、**最有效的方式**：系统会根据评估结果倾向调用那些高性能版本的Agent，或者提前规避已知问题（如建模结果总偏高则加入矫正步骤）。因此，在架构视角下，评估Agent闭环连接了**输出质量**与**模块优化**，保障信息获取、建模等基础Agent与核心智能模块协作越来越顺畅，**整体性能随时间提升**。

综上所述，本多Agent科研创意系统的核心模块在架构上与信息获取Agent、建模Agent紧密融合，共同完成从问题提出到方案输出的过程。主Agent通过黑板将**检索**和**建模**引入解题流程，验证Agent和批判Agent确保**知识结果与方案质量**，实验设计Agent让抽象方案落地为**实验可行**，报告生成Agent把所有内容**汇总呈现**给用户，而控制调度模块与评估Agent在幕后确保**过程有序**且**系统自我改进**。所有模块围绕黑板这一共享内存互动，各模块输出在黑板上变成**下一模块的输入**。这种架构保证了**松耦合**（通过黑板通信而非直连）和**强协同**（通过事件驱动实现及时互动），使系统具备类似人类科研团队的分工合作能力，同时通过内部反馈不断提高。这份技术方案蓝图为多Agent协同创新系统的实现提供了清晰的模块划分和交互设计基础，接下来可据此进行具体开发和部署，实现面向科研创新场景的智能协作平台。
