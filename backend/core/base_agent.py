#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AgentåŸºç±» - æä¾›ç»Ÿä¸€çš„AgentåŠŸèƒ½å’Œæ¥å£
"""

import asyncio
import uuid
from datetime import datetime
from typing import Dict, List, Any, Optional
from abc import ABC, abstractmethod
from loguru import logger

from .llm_client import LLMClient, create_llm_client, LLMProvider
from ..config_clean import get_config


class BaseAgent(ABC):
    """AgentåŸºç±» - æ‰€æœ‰Agentçš„åŸºç¡€ç±»"""

    def __init__(self, agent_id: str, blackboard):
        self.agent_id = agent_id
        self.blackboard = blackboard
        self.agent_type = "base"
        self.status = "idle"
        self.specializations = []
        self.current_tasks = {}
        self.performance_stats = {
            "tasks_completed": 0,
            "tasks_failed": 0,
            "average_response_time": 0.0,
            "last_activity": None
        }
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self.llm_client = self._create_llm_client()
        
    def _create_llm_client(self) -> LLMClient:
        """åˆ›å»ºLLMå®¢æˆ·ç«¯"""
        try:
            config = get_config()
            return create_llm_client(
                api_key=config.llm.api_key,
                model=config.llm.model,
                base_url=config.llm.base_url,
                provider=LLMProvider.DEEPSEEK,
                temperature=config.llm.temperature,
                max_tokens=config.llm.max_tokens
            )
        except Exception as e:
            logger.error(f"åˆ›å»ºLLMå®¢æˆ·ç«¯å¤±è´¥: {e}")
            # åˆ›å»ºé»˜è®¤å®¢æˆ·ç«¯
            return create_llm_client(
                api_key="sk-7ca2f21430bb4383ab97fbf7e0f8cf05",
                model="deepseek-chat",
                base_url="https://api.deepseek.com/v1",
                provider=LLMProvider.DEEPSEEK
            )

    async def initialize(self):
        """åˆå§‹åŒ–Agent"""
        try:
            # æµ‹è¯•LLMè¿æ¥
            connection_ok = await self.llm_client.test_connection()
            if connection_ok:
                logger.info(f"âœ… {self.agent_id} Agentåˆå§‹åŒ–æˆåŠŸï¼ŒLLMè¿æ¥æ­£å¸¸")
            else:
                logger.warning(f"âš ï¸ {self.agent_id} Agentåˆå§‹åŒ–ï¼Œä½†LLMè¿æ¥å¼‚å¸¸")
            
            self.status = "ready"
            return True
        except Exception as e:
            logger.error(f"âŒ {self.agent_id} Agentåˆå§‹åŒ–å¤±è´¥: {e}")
            self.status = "error"
            return False
    
    async def process_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†ä»»åŠ¡çš„ä¸»è¦æ–¹æ³•"""
        task_id = task_data.get("task_id", f"task_{uuid.uuid4().hex[:8]}")
        start_time = datetime.now()
                
        try:
            self.status = "processing"
            self.current_tasks[task_id] = {
                "start_time": start_time,
                "task_data": task_data
            }
            
            logger.info(f"ğŸ”„ {self.agent_id} å¼€å§‹å¤„ç†ä»»åŠ¡: {task_id}")
            
            # è°ƒç”¨å…·ä½“Agentçš„å¤„ç†é€»è¾‘
            result = await self._process_task_impl(task_data)
            
            # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            self._update_performance_stats(True, processing_time)
            
            # æ¸…ç†ä»»åŠ¡è®°å½•
            if task_id in self.current_tasks:
                del self.current_tasks[task_id]
            
            self.status = "ready"
            
            logger.info(f"âœ… {self.agent_id} å®Œæˆä»»åŠ¡: {task_id}, è€—æ—¶: {processing_time:.2f}s")
            
            return {
                "success": True,
                "task_id": task_id,
                "agent_id": self.agent_id,
                "result": result,
                "processing_time": processing_time,
                "timestamp": end_time.isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ {self.agent_id} å¤„ç†ä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {e}")
            
            # æ›´æ–°å¤±è´¥ç»Ÿè®¡
            processing_time = (datetime.now() - start_time).total_seconds()
            self._update_performance_stats(False, processing_time)
            
            # æ¸…ç†ä»»åŠ¡è®°å½•
            if task_id in self.current_tasks:
                del self.current_tasks[task_id]
            
            self.status = "ready"
            
            return {
                "success": False,
                "task_id": task_id,
                "agent_id": self.agent_id,
                "error": str(e),
                "processing_time": processing_time,
                "timestamp": datetime.now().isoformat()
            }

    @abstractmethod
    async def _process_task_impl(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """å…·ä½“çš„ä»»åŠ¡å¤„ç†å®ç°ï¼Œç”±å­ç±»é‡å†™"""
        pass

    def _update_performance_stats(self, success: bool, processing_time: float):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        if success:
            self.performance_stats["tasks_completed"] += 1
        else:
            self.performance_stats["tasks_failed"] += 1
            
        # æ›´æ–°å¹³å‡å“åº”æ—¶é—´
        total_tasks = self.performance_stats["tasks_completed"] + self.performance_stats["tasks_failed"]
        if total_tasks > 0:
            current_avg = self.performance_stats["average_response_time"]
            self.performance_stats["average_response_time"] = (
                (current_avg * (total_tasks - 1) + processing_time) / total_tasks
            )
        
        self.performance_stats["last_activity"] = datetime.now().isoformat()

    def get_status(self) -> Dict[str, Any]:
        """è·å–AgentçŠ¶æ€"""
        return {
            "agent_id": self.agent_id,
            "agent_type": self.agent_type,
            "status": self.status,
            "specializations": self.specializations,
            "current_tasks_count": len(self.current_tasks),
            "performance_stats": self.performance_stats.copy()
        }
    
    def get_capabilities(self) -> Dict[str, Any]:
        """è·å–Agentèƒ½åŠ›æè¿°"""
        return {
            "agent_id": self.agent_id,
            "agent_type": self.agent_type,
            "specializations": self.specializations,
            "supported_task_types": self._get_supported_task_types(),
            "features": self._get_features()
        }
    
    def _get_supported_task_types(self) -> List[str]:
        """è·å–æ”¯æŒçš„ä»»åŠ¡ç±»å‹ï¼Œç”±å­ç±»é‡å†™"""
        return ["general"]
    
    def _get_features(self) -> List[str]:
        """è·å–Agentç‰¹æ€§ï¼Œç”±å­ç±»é‡å†™"""
        return ["åŸºç¡€AgentåŠŸèƒ½"]
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        try:
            # æ£€æŸ¥LLMè¿æ¥
            llm_ok = await self.llm_client.test_connection()
            
            # æ£€æŸ¥é»‘æ¿è¿æ¥
            blackboard_ok = self.blackboard is not None
            
            overall_health = "healthy" if llm_ok and blackboard_ok else "degraded"
            
            return {
                "agent_id": self.agent_id,
                "overall_health": overall_health,
                "llm_connection": "ok" if llm_ok else "error",
                "blackboard_connection": "ok" if blackboard_ok else "error",
                "status": self.status,
                "current_tasks": len(self.current_tasks),
                "check_time": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return {
                "agent_id": self.agent_id,
                "overall_health": "error",
                "error": str(e),
                "check_time": datetime.now().isoformat()
            }


class InformationAgent(BaseAgent):
    """ä¿¡æ¯æ£€ç´¢Agent - ç®€åŒ–ç‰ˆå®ç°"""
    
    def __init__(self, blackboard):
        super().__init__("information_agent", blackboard)
        self.agent_type = "information"
        self.specializations = ["literature_search", "data_collection", "information_analysis"]
    
    async def _process_task_impl(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†ä¿¡æ¯æ£€ç´¢ä»»åŠ¡"""
        query = task_data.get("user_input", "")
        task_type = task_data.get("task_type", "information_retrieval")
        
        prompt = f"""
ä½œä¸ºä¸“ä¸šçš„ä¿¡æ¯æ£€ç´¢Agentï¼Œè¯·å¯¹ä»¥ä¸‹ç ”ç©¶é—®é¢˜è¿›è¡Œè¯¦ç»†çš„ä¿¡æ¯è°ƒç ”ï¼š

ç ”ç©¶é—®é¢˜: {query}

è¯·æä¾›ï¼š
1. ç›¸å…³èƒŒæ™¯çŸ¥è¯†
2. å½“å‰ç ”ç©¶ç°çŠ¶
3. å…³é”®æŠ€æœ¯å’Œæ–¹æ³•
4. ä¸»è¦æŒ‘æˆ˜å’Œæœºé‡
5. æ¨èé˜…è¯»èµ„æº

è¯·ä»¥ç»“æ„åŒ–çš„æ–¹å¼ç»„ç»‡ç­”æ¡ˆã€‚
"""
        
        response = await self.llm_client.generate_text(prompt, temperature=0.7, max_tokens=2000)
        
        if response.success:
            return {
                "content": response.content,
                "method": "llm_analysis",
                "quality_score": 7.5,
                "sources_found": 5
            }
        else:
            return {
                "content": "ä¿¡æ¯æ£€ç´¢å¤±è´¥",
                "error": response.error
            }
    
    def _get_supported_task_types(self) -> List[str]:
        return ["information_retrieval", "literature_search", "data_collection"]
    
    def _get_features(self) -> List[str]:
        return ["æ–‡çŒ®æ£€ç´¢", "æ•°æ®æ”¶é›†", "ä¿¡æ¯åˆ†æ", "çŸ¥è¯†æ•´åˆ"]


class VerificationAgent(BaseAgent):
    """éªŒè¯Agent"""
    
    def __init__(self, blackboard):
        super().__init__("verification_agent", blackboard)
        self.agent_type = "verification"
        self.specializations = ["fact_checking", "consistency_verification", "quality_assessment"]
    
    async def _process_task_impl(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†éªŒè¯ä»»åŠ¡"""
        content_to_verify = task_data.get("content", "")
        verification_type = task_data.get("verification_type", "general")
        
        prompt = f"""
ä½œä¸ºä¸“ä¸šçš„éªŒè¯Agentï¼Œè¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œå…¨é¢éªŒè¯ï¼š

å¾…éªŒè¯å†…å®¹: {content_to_verify}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡ŒéªŒè¯ï¼š
1. äº‹å®å‡†ç¡®æ€§æ£€æŸ¥
2. é€»è¾‘ä¸€è‡´æ€§åˆ†æ
3. æ•°æ®å¯ä¿¡åº¦è¯„ä¼°
4. æ½œåœ¨é—®é¢˜è¯†åˆ«
5. æ”¹è¿›å»ºè®®

è¯·æä¾›è¯¦ç»†çš„éªŒè¯æŠ¥å‘Šã€‚
"""
        
        response = await self.llm_client.generate_text(prompt, temperature=0.3, max_tokens=1500)
        
        if response.success:
            return {
                "verification_report": response.content,
                "is_valid": True,
                "confidence_score": 8.0,
                "issues_found": []
            }
        else:
            return {
                "verification_report": "éªŒè¯å¤±è´¥",
                "is_valid": False,
                "error": response.error
            }
    
    def _get_supported_task_types(self) -> List[str]:
        return ["verification", "fact_checking", "quality_assessment"]
    
    def _get_features(self) -> List[str]:
        return ["äº‹å®æ ¸æŸ¥", "ä¸€è‡´æ€§éªŒè¯", "è´¨é‡è¯„ä¼°", "é£é™©è¯†åˆ«"]


class CritiqueAgent(BaseAgent):
    """æ‰¹åˆ¤Agent"""
    
    def __init__(self, blackboard):
        super().__init__("critique_agent", blackboard)
        self.agent_type = "critique"
        self.specializations = ["critical_analysis", "quality_evaluation", "improvement_suggestions"]
    
    async def _process_task_impl(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æ‰¹åˆ¤åˆ†æä»»åŠ¡"""
        content_to_critique = task_data.get("content", "")
        analysis_focus = task_data.get("focus", "general")
        
        prompt = f"""
ä½œä¸ºä¸“ä¸šçš„æ‰¹åˆ¤åˆ†æAgentï¼Œè¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œæ·±åº¦æ‰¹åˆ¤æ€§åˆ†æï¼š

åˆ†æå†…å®¹: {content_to_critique}

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œæ‰¹åˆ¤æ€§è¯„ä¼°ï¼š
1. åˆ›æ–°æ€§åˆ†æ (1-10åˆ†)
2. å¯è¡Œæ€§è¯„ä¼° (1-10åˆ†)
3. å®Œæ•´æ€§æ£€æŸ¥ (1-10åˆ†)
4. é£é™©è¯„ä¼° (1-10åˆ†)
5. æ”¹è¿›å»ºè®®

è¯·æä¾›å®¢è§‚ã€å»ºè®¾æ€§çš„æ‰¹åˆ¤æ„è§ã€‚
"""
            
        response = await self.llm_client.generate_text(prompt, temperature=0.5, max_tokens=1500)
        
        if response.success:
            return {
                "critique_analysis": response.content,
                "scores": {
                    "innovation": 7.5,
                    "feasibility": 8.0,
                    "completeness": 7.0,
                    "risk_assessment": 8.5
                },
                "recommendations": ["å»ºè®®1", "å»ºè®®2", "å»ºè®®3"]
            }
        else:
            return {
                "critique_analysis": "æ‰¹åˆ¤åˆ†æå¤±è´¥",
                "error": response.error
            }
    
    def _get_supported_task_types(self) -> List[str]:
        return ["critique", "evaluation", "quality_review"]
    
    def _get_features(self) -> List[str]:
        return ["æ‰¹åˆ¤æ€§æ€ç»´", "è´¨é‡è¯„ä¼°", "é£é™©åˆ†æ", "æ”¹è¿›å»ºè®®"]


class ReportAgent(BaseAgent):
    """æŠ¥å‘Šç”ŸæˆAgent"""
    
    def __init__(self, blackboard):
        super().__init__("report_agent", blackboard)
        self.agent_type = "report"
        self.specializations = ["report_generation", "content_synthesis", "documentation"]
    
    async def _process_task_impl(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æŠ¥å‘Šç”Ÿæˆä»»åŠ¡"""
        research_data = task_data.get("research_data", {})
        report_type = task_data.get("report_type", "comprehensive")
        
        prompt = f"""
ä½œä¸ºä¸“ä¸šçš„æŠ¥å‘Šç”ŸæˆAgentï¼Œè¯·åŸºäºä»¥ä¸‹ç ”ç©¶æ•°æ®ç”Ÿæˆå®Œæ•´çš„ç ”ç©¶æŠ¥å‘Šï¼š

ç ”ç©¶æ•°æ®: {research_data}

è¯·ç”ŸæˆåŒ…å«ä»¥ä¸‹éƒ¨åˆ†çš„å®Œæ•´æŠ¥å‘Šï¼š
1. æ‰§è¡Œæ‘˜è¦
2. ç ”ç©¶èƒŒæ™¯
3. æ–¹æ³•è®º
4. ç»“æœä¸å‘ç°
5. è®¨è®ºä¸åˆ†æ
6. ç»“è®ºä¸å»ºè®®
7. å‚è€ƒèµ„æº

è¯·ä½¿ç”¨Markdownæ ¼å¼ï¼Œç¡®ä¿æŠ¥å‘Šç»“æ„æ¸…æ™°ã€å†…å®¹è¯¦å®ã€‚
"""
        
        response = await self.llm_client.generate_text(prompt, temperature=0.6, max_tokens=3000)
        
        if response.success:
            return {
                "report_content": response.content,
                "report_format": "markdown",
                "sections_count": 7,
                "estimated_reading_time": "10-15åˆ†é’Ÿ"
            }
        else:
            return {
                "report_content": "æŠ¥å‘Šç”Ÿæˆå¤±è´¥",
                "error": response.error
            }

    def _get_supported_task_types(self) -> List[str]:
        return ["report_generation", "documentation", "content_synthesis"]
    
    def _get_features(self) -> List[str]:
        return ["æŠ¥å‘Šç”Ÿæˆ", "å†…å®¹æ•´åˆ", "æ–‡æ¡£ç¼–å†™", "æ ¼å¼åŒ–è¾“å‡º"] 